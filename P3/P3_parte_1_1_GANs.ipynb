{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2Ubr-O3iQVy"
   },
   "source": [
    "# **Práctica 3**: GANs\n",
    "# Parte 1: GANs simples\n",
    "\n",
    "Simplificación de:\n",
    "https://medium.com/@mattiaspinelli/simple-generative-adversarial-network-gans-with-keras-1fe578e44a87\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-RCqufHNAzL"
   },
   "source": [
    "### Ejercicio prelab:\n",
    "Lee y ejecuta el siguiente código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DVKZamBiY1l"
   },
   "source": [
    "Importamos librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McZH6Y1mik4x"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from IPython.core.debugger import Tracer\n",
    "\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aoIxiT289bru"
   },
   "outputs": [],
   "source": [
    "plt.switch_backend('agg') # allows code to run without a system DISPLAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgmtA9QcibR6"
   },
   "source": [
    "Leemos datos MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R63eKjChOsb9"
   },
   "outputs": [],
   "source": [
    "# Datos\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    " \n",
    "X_train = np.expand_dims(X_train, axis=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sWQh5vWih7I"
   },
   "source": [
    "# Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Il0-XGQTikVT"
   },
   "source": [
    "### Diseñamos modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vh8i1dncinx6"
   },
   "source": [
    "Dimensiones y optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLBS0ttgOsik"
   },
   "outputs": [],
   "source": [
    "width=28\n",
    "height=28\n",
    "channels=1\n",
    "\n",
    "in_shape = X_train.shape\n",
    "in_shape = in_shape[1:]\n",
    "OPTIMZADOR_ADAM = Adam(learning_rate=0.0002, beta_1=0.5, decay=8e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fUQeX51irG8"
   },
   "source": [
    "Modelo del Generador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n61oufagOs0S"
   },
   "outputs": [],
   "source": [
    "model_gen = Sequential()\n",
    "model_gen.add(Dense(256, input_shape=(100,)))\n",
    "model_gen.add(LeakyReLU(alpha=0.2))\n",
    "model_gen.add(BatchNormalization(momentum=0.8))\n",
    "model_gen.add(Dense(512))\n",
    "model_gen.add(LeakyReLU(alpha=0.2))\n",
    "model_gen.add(BatchNormalization(momentum=0.8))\n",
    "model_gen.add(Dense(1024))\n",
    "model_gen.add(LeakyReLU(alpha=0.2))\n",
    "model_gen.add(BatchNormalization(momentum=0.8))\n",
    "model_gen.add(Dense(np.prod(in_shape), activation='tanh'))\n",
    "model_gen.add(Reshape(in_shape))\n",
    "model_gen.summary()\n",
    "model_gen.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4HXDL6liu8T"
   },
   "source": [
    "Modelo del discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "18PD5EQ0Oztl"
   },
   "outputs": [],
   "source": [
    "model_Disc = Sequential()\n",
    "model_Disc.add(Flatten(input_shape=in_shape))\n",
    "model_Disc.add(Dense(128, input_shape=in_shape))\n",
    "model_Disc.add(LeakyReLU(alpha=0.2))\n",
    "model_Disc.add(Dense(64))\n",
    "model_Disc.add(LeakyReLU(alpha=0.2))\n",
    "model_Disc.add(Dense(1, activation='sigmoid'))\n",
    "model_Disc.summary()\n",
    "model_Disc.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-MZLXWJHix-e"
   },
   "source": [
    "Modelo combinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zQJKNVFO0OJ"
   },
   "outputs": [],
   "source": [
    "model_gan = Sequential()\n",
    "model_gan.add(model_gen)\n",
    "model_gan.add(model_Disc)\n",
    "model_gan.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "\n",
    "model_gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n1hx7LW5i5Qh"
   },
   "source": [
    "# Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KsdNINcjik9u",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parámetros del entrenamiento\n",
    "epochs = 5000\n",
    "batch = 10\n",
    "\n",
    "# Bucle entrenamiento\n",
    "\n",
    "DD_loss = np.zeros((epochs,))\n",
    "GG_loss = np.zeros((epochs,))\n",
    "\n",
    "for cnt in range(epochs):\n",
    "\n",
    "    ## Entrenamos discriminador\n",
    "        # Imágenes reales\n",
    "    random_index = np.random.randint(0, len(X_train) - np.int64(batch/2))\n",
    "    legit_images = X_train[random_index : random_index + np.int64(batch/2)].reshape((np.int64(batch/2),)+in_shape)\n",
    "        # Imágenes sintéticas\n",
    "    gen_noise = np.random.normal(0, 1, (np.int64(batch/2), 100))\n",
    "    syntetic_images = model_gen.predict(gen_noise)\n",
    "        # Combinamos imágenes reales y sintéticas\n",
    "    x_combined_batch = np.concatenate((legit_images, syntetic_images))\n",
    "    y_combined_batch = np.concatenate((np.ones((np.int64(batch/2), 1)), np.zeros((np.int64(batch/2), 1))))\n",
    "        # Entrenamos discriminador\n",
    "    d_loss = model_Disc.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "\n",
    "\n",
    "    ## Entrenamos generador\n",
    "        # Imágenes sintéticasnp.zeros\n",
    "    noise = np.random.normal(0, 1, (batch, 100))\n",
    "    y_mislabled = np.ones((batch, 1))\n",
    "        # Entremaos generador\n",
    "    g_loss = model_gan.train_on_batch(noise, y_mislabled)\n",
    "\n",
    "    ## Evolución entrenamiento\n",
    "    print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))\n",
    "\n",
    "    DD_loss[cnt] = d_loss[0]\n",
    "    GG_loss[cnt] = g_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UOP9C32sjcb4"
   },
   "source": [
    "Curvas de aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zAZEymeE57_"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.figure\n",
    "plt.plot(DD_loss)\n",
    "plt.plot(GG_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ylftDLjmUNy6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbTD75ISbYyZ"
   },
   "source": [
    "# Generar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwgeR1y9bayP"
   },
   "outputs": [],
   "source": [
    "# Generamos imagen sintética\n",
    "gen_noise = np.random.normal(0, 1, (np.int64(10), 100))\n",
    "syntetic_images = model_gen.predict(gen_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mNjaZcbbkQG"
   },
   "outputs": [],
   "source": [
    "# Mostramos imagen sintética\n",
    "plt.imshow(syntetic_images[5,:,:,0],cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6iTzlK9bn4u"
   },
   "outputs": [],
   "source": [
    "# Esto es una imagen real (por comparar)\n",
    "plt.imshow(X_train[0,:,:,0],cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGjuKpjHfz62"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_skeNN9jtSi"
   },
   "source": [
    "# Ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM-13-VNju5S"
   },
   "source": [
    "### Ejercicio 1:\n",
    "\n",
    "Modifica el código para incluir la generación de las etiquetas:\n",
    "\n",
    "Modelo cGAN:\n",
    "\n",
    "- En lugar de cargar solo las imágenes de MNIST, cargamos tanto las imágenes como las etiquetas.\n",
    "\n",
    "- Al entrenar el generador, debemos proporcionar tanto ruido aleatorio como etiquetas generadas aleatoriamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "APx32IsG9brx"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import initializers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKrBJACh9brx"
   },
   "outputs": [],
   "source": [
    "# Definir las variables relevantes\n",
    "# Datos\n",
    "# Load MNIST  \n",
    "(X_train, y_train), (_, _) = mnist.load_data()\n",
    "print('X_train shape 1 :', X_train.shape)\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "print('X_train shape 2:', X_train.shape)\n",
    "\n",
    "num_classes = 10\n",
    "#y_train = tf.keras.utils.to_categorical(y_train, num_classes) # Convertir etiquetas en vectores one-hot.. Se puede hacer con embebing dentro de la red\n",
    "\n",
    "# Definir dimensiones de entrada\n",
    "in_shape = (28,28,1)\n",
    "img_dim = np.prod (in_shape)\n",
    "init = initializers.RandomNormal(stddev=0.01)\n",
    "latent_dim = 100\n",
    "num_classes = 10\n",
    "\n",
    "#optimizador\n",
    "OPTIMZADOR_ADAM = Adam(learning_rate=0.0002, beta_1=0.5, decay=8e-8)\n",
    "\n",
    "# Visualizar imagenes-labels reales // imagenes-labels generaadas\n",
    "def generate_images(generator, epoch):\n",
    "    rows, cols = 10, 10\n",
    "    noise  = np.random.normal (0, 1, (rows * cols, 100))\n",
    "    labels = np.random.randint (0, num_classes, rows * cols).reshape(-1, 1)  #y_train [:rows * cols]\n",
    "    images = generator.predict ([noise, labels])\n",
    "     \n",
    "    images = np.reshape(images, (images.shape[0], 28, 28, 1))\n",
    "    images = 0.5 * images + 0.5 # escalar de [-1,1] a [0,1]\n",
    "    images = np.uint8(255 * images) # escalar a [0, 255]\n",
    "     \n",
    "    labels_in = labels.ravel()\n",
    "    \n",
    "    for i in range(rows):\n",
    "        row = images[i*cols:(i+1)*cols]\n",
    "        \n",
    "        row = np.concatenate(row, axis=1)\n",
    "        \n",
    "        plt.title(f'{labels_in[i*cols:(i+1)*cols]}')\n",
    "        plt.imshow(row[:,:,0])\n",
    "        plt.axis('off')\n",
    "        #plt.title(f\"Epoch {epoch} - Row {i}\")\n",
    "        plt.tick_params(axis='both',labelsize=14)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvTCA0bh9bry"
   },
   "outputs": [],
   "source": [
    "# ***********************************\n",
    "# Definir modelo generador\n",
    "# ***********************************\n",
    "generator = Sequential()\n",
    "# Input layer  \n",
    "generator.add(Dense(128, input_shape=(latent_dim,), kernel_initializer=init))\n",
    "generator.add(LeakyReLU(alpha = 0.2))\n",
    "generator.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "generator.add(Dense(256, kernel_initializer = init))\n",
    "generator.add(LeakyReLU(alpha = 0.2))\n",
    "generator.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "generator.add(Dense(512, kernel_initializer = init))\n",
    "generator.add(LeakyReLU(alpha = 0.2))\n",
    "generator.add(BatchNormalization(momentum = 0.8))\n",
    "\n",
    "# Output layer\n",
    "generator.add(Dense(img_dim, activation = 'tanh'))\n",
    "\n",
    "# se pasa también la eiqueta de la imagen\n",
    "# Create label embeddings, one-hot (label)\n",
    "label = Input(shape=(1,), dtype='int32')\n",
    "label_embedding = Embedding(num_classes, latent_dim)(label)\n",
    "label_embedding = Flatten()(label_embedding)\n",
    "\n",
    "# latent space\n",
    "z = Input(shape=(latent_dim,))\n",
    "\n",
    "# Output image\n",
    "img = generator(Multiply()([z, label_embedding]))\n",
    "\n",
    "# Generator with condition input\n",
    "generator = Model([z, label], img)\n",
    "generator.summary()\n",
    "plot_model(generator, to_file='cgan_generator.png', show_shapes=True)\n",
    "# ***********************************\n",
    "# Definir modelo discriminador\n",
    "# ***********************************\n",
    "\n",
    "# Discriminator network\n",
    "discriminator = Sequential()\n",
    " \n",
    "# Input layer  \n",
    " \n",
    "discriminator.add(Flatten(input_shape = in_shape))\n",
    "discriminator.add(Dense(128, kernel_initializer=init))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dense(64, kernel_initializer=init))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "# Output layer\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# se pasa también la eiqueta de la imagen\n",
    "label_d = Input(shape=(1,), dtype='int32')\n",
    "label_embedding_d = Embedding(num_classes, img_dim)(label_d)\n",
    "label_embedding_d = Flatten()(label_embedding_d)\n",
    "label_embedding_d = Reshape((28, 28, 1))(label_embedding_d)\n",
    " \n",
    "# image dimension 28x28\n",
    "# Image input\n",
    "img_d = Input (shape = in_shape)\n",
    "# Output image\n",
    "validity = discriminator(Multiply()([img_d, label_embedding_d]))\n",
    "\n",
    "# Discriminator with condition input\n",
    "discriminator = Model([img_d, label_d], validity)\n",
    "discriminator.summary()\n",
    "plot_model(discriminator, to_file='cgan_discriminator.png', show_shapes=True)\n",
    "# Compilar modelos\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])\n",
    "#generator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "\n",
    "# ***********************************\n",
    "# Definir modelo cGan\n",
    "# ***********************************\n",
    "gen_input = Input(shape=(latent_dim,))\n",
    "gen_label = Input(shape=(1,), dtype='int32')\n",
    "synthetic_image = generator([gen_input, gen_label])\n",
    "synthetic_image_reshaped = Reshape((28, 28, 1))(synthetic_image)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator([synthetic_image_reshaped, gen_label])\n",
    "cGan = Model([gen_input, gen_label], validity)\n",
    "cGan.summary()\n",
    "plot_model(cGan, to_file='cgan_model.png', show_shapes=True)\n",
    "cGan.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rc-lf4Og9bry",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parámetros del entrenamiento\n",
    "epochs = 2000 \n",
    "batch_size = 64\n",
    "\n",
    "# Bucle entrenamiento\n",
    "DD_loss = np.zeros((epochs+1,))\n",
    "GG_loss = np.zeros((epochs+1,))\n",
    " \n",
    "\n",
    "for cnt in range(epochs + 1):\n",
    "   \n",
    "    # ***********************************\n",
    "    # Paso 1: Entrenar el discriminador\n",
    "    discriminator.trainable = True\n",
    "    # ***********************************\n",
    "    \n",
    "    \n",
    "    # Genera un conjunto de imágenes reales\n",
    "    idx = np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "    #idx0 = cnt*batch_size\n",
    "    #idx1 = (cnt+1)*batch_size\n",
    "\n",
    "    real_images = X_train[idx]#X_train[idx0:idx1]\n",
    "    real_labels = y_train[idx].reshape(-1, 1)#y_train[idx0:idx1].reshape(-1, 1)\n",
    "\n",
    "    #print(real_images.shape)\n",
    "    #print(real_labels.shape)\n",
    "    #print(real_labels)\n",
    "\n",
    "    # Genera un conjunto de imágenes falsas\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    fake_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "    fake_images = generator.predict([noise,fake_labels])\n",
    "    #print(fake_images.shape)\n",
    "    fake_images = np.reshape(fake_images, (fake_images.shape[0], 28, 28, 1))\n",
    "    \n",
    "    # Entrenamiento discriminador\n",
    "    \n",
    "    #print(real_images.shape)\n",
    "    #print(real_labels.shape)\n",
    "\n",
    "    #print(fake_images.shape)\n",
    "    #print(fake_labels.shape)\n",
    "\n",
    "    d_loss_real = discriminator.train_on_batch([real_images, real_labels], np.ones(batch_size))\n",
    "    d_loss_fake = discriminator.train_on_batch([fake_images, fake_labels], np.zeros(batch_size))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ***********************************\n",
    "    # Paso 2: Entrenar el generador\n",
    "    discriminator.trainable = False\n",
    "    # ***********************************\n",
    "    gen_input  = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    gen_labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "    y_gen = np.ones(batch_size)\n",
    "    g_loss = cGan.train_on_batch([gen_input, gen_labels],y_gen)\n",
    "\n",
    "    # Registrar el progreso del entrenamiento\n",
    "    DD_loss[cnt] = d_loss[0]\n",
    "    GG_loss[cnt] = g_loss [0]\n",
    "\n",
    "    print(f'Epoch: {cnt}/{epochs} \\t Discriminator Loss: {d_loss[0]} \\t Generator Loss: {g_loss[0]}')\n",
    "    # Imprimir progreso cada 100 iteraciones\n",
    "    if cnt % 100 == 0:\n",
    "        print(y_train.shape)\n",
    "        generate_images(generator, cnt)\n",
    "\n",
    "        samples = 10\n",
    "        z = np.random.normal(loc=0, scale=1, size=(samples, latent_dim))\n",
    "        labels = np.arange(0, 10).reshape(-1, 1)\n",
    "\n",
    "        x_fake = generator.predict([z, labels])\n",
    "        x_fake =  np.reshape(x_fake, (x_fake.shape[0], 28, 28, 1))\n",
    "        for k in range(samples):\n",
    "            plt.subplot(2, 5, k+1)\n",
    "            plt.title(f'Label: {labels[k]}')\n",
    "            plt.imshow(x_fake[k,:,:,0].reshape(28, 28), cmap='gray')\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X7Vpf22S9brz"
   },
   "outputs": [],
   "source": [
    "# Generar imágenes con etiquetas aleatorias\n",
    "n_to_show   = 10\n",
    "latent_dim  = 100\n",
    "num_classes = 10\n",
    "\n",
    "labels = np.random.randint(0, num_classes, n_to_show).reshape(-1, 1) \n",
    "z = np.random.normal(loc=0, scale=1, size=(n_to_show, latent_dim))\n",
    "labels = np.random.randint(0, num_classes, n_to_show).reshape(-1, 1) \n",
    "\n",
    "x_fake = generator.predict([z, labels])\n",
    "x_fake =  np.reshape(x_fake, (x_fake.shape[0], 28, 28, 1))\n",
    "\n",
    "# Mostrar imágenes generadas con sus etiquetas\n",
    "fig, axs = plt.subplots(1, n_to_show, figsize=(12,4))\n",
    "for i in range(n_to_show):\n",
    "    axs[i].set_title(f'Label: {labels[i]}')\n",
    "    axs[i].imshow(x_fake[i, :,:,0].reshape(28, 28), cmap='gray')\n",
    "    axs[i].axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3T6GUG9a9brz"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.plot(DD_loss, label=\"Discriminator Loss\")\n",
    "plt.plot(GG_loss, label=\"Generator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con 1000 epocs ya sería suficiente para generar imagenes similares a las reales y no llega a detectar si son falsas o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXuQqWse9brz"
   },
   "source": [
    "# OTRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yjcLslU29brz",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir modelo generador\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate, Lambda\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import initializers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "# Load MNIST  \n",
    "(X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3) # 28,28,1\n",
    "\n",
    "# Definimos la dimensión de las etiquetas\n",
    "num_classes = 10\n",
    " \n",
    "# Definimos la dimensión de las imágenes\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "# Tamaño de entrada de las imágenes\n",
    "in_shape = (img_rows, img_cols, channels)\n",
    "\n",
    "img_dim = np.prod (in_shape)\n",
    " \n",
    "# Tamaño de entrada de la etiqueta\n",
    "label_shape = (1,)\n",
    "\n",
    "# Definimos el número de neuronas en la capa oculta\n",
    "hidden_dim = 128\n",
    "\n",
    "# Función de activación para las capas densas\n",
    "activation = 'relu'# 'LeakyRelu'\n",
    "\n",
    "# Tamaño del vector de ruido\n",
    "latent_dim = 100\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # y_true es una lista con dos elementos: la imagen real y la etiqueta real\n",
    "    # y_pred es una lista con dos elementos: la imagen generada y la etiqueta generada\n",
    "    img_loss = tf.keras.losses.binary_crossentropy(y_true[0], y_pred[0])\n",
    "    label_loss = tf.keras.losses.categorical_crossentropy(y_true[1], y_pred[1])\n",
    "\n",
    "    return img_loss + label_loss\n",
    "\n",
    "def cgan_loss(y_true, y_pred):\n",
    "    # y_true es una lista con dos elementos: la imagen real y la etiqueta real\n",
    "    # y_pred es una lista con dos elementos: la imagen generada y la etiqueta generada\n",
    "\n",
    "    # Pérdida en la generación de imágenes\n",
    "    img_loss = tf.keras.losses.binary_crossentropy(y_true[0], y_pred[0])\n",
    "\n",
    "    # Pérdida en la generación de etiquetas\n",
    "    label_loss = tf.keras.losses.binary_crossentropy(y_true[1], y_pred[1])\n",
    "\n",
    "    # Pérdida total\n",
    "    total_loss = img_loss + label_loss\n",
    "\n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "# Función para crear el discriminador\n",
    "def build_discriminator(in_shape,img_dim, label_shape):\n",
    "    # Input layer\n",
    "    dis_input = Input(shape=in_shape)\n",
    "    label_d = Input(shape=(1), dtype='int32')\n",
    "\n",
    "    # Create label embeddings, one-hot (label)\n",
    "    label_embedding_d = Embedding(num_classes, img_dim)(label_d)\n",
    "    label_embedding_d = Flatten()(label_embedding_d)\n",
    "    label_embedding_d = Reshape((28, 28, 1))(label_embedding_d)\n",
    "\n",
    "    # Concatenate inputs\n",
    "    concat_d = Multiply()([dis_input, label_embedding_d])\n",
    "\n",
    "    # Hidden layers\n",
    "    dis_layer1 = Dense(128, kernel_initializer='glorot_uniform')(Flatten()(concat_d))\n",
    "    dis_layer1 = LeakyReLU(alpha=0.2)(dis_layer1)\n",
    "\n",
    "    dis_layer2 = Dense(64, kernel_initializer='glorot_uniform')(dis_layer1)\n",
    "    dis_layer2 = LeakyReLU(alpha=0.2)(dis_layer2)\n",
    "\n",
    "    # Output layer\n",
    "    dis_output = Dense(1, activation='sigmoid')(dis_layer2)\n",
    "\n",
    "    # Modelo del discriminador\n",
    "    # Discriminator with condition input\n",
    "    discriminator = Model([dis_input, label_d], dis_output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return discriminator\n",
    " \n",
    "# Función para crear el generador\n",
    "def build_generator(latent_dim, label_shape, in_shape):\n",
    "    # Input layer\n",
    "    gen_input = Input(shape=(latent_dim,))\n",
    "    label = Input(shape=label_shape)\n",
    "\n",
    "    # Create label embeddings, one-hot (label)\n",
    "    label_embedding = Embedding(num_classes, latent_dim)(label)\n",
    "    label_embedding = Flatten()(label_embedding)\n",
    "    \n",
    "    # Concatenar la etiqueta y el vector de ruido\n",
    "    merged_layer = Multiply()([gen_input, label_embedding]) #Concatenate()([noise_input, label_input])\n",
    "\n",
    "    gen_layer1 = Dense(128, kernel_initializer='glorot_uniform')(merged_layer)\n",
    "    gen_layer1 = LeakyReLU(alpha=0.2)(gen_layer1)\n",
    "    gen_layer1 = BatchNormalization(momentum=0.8)(gen_layer1)\n",
    "\n",
    "    # Capas densas para la red neuronal del generador\n",
    "    x = Dense(256, activation=activation)(gen_layer1)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    x = BatchNormalization(momentum = 0.8)(x)\n",
    "                                 \n",
    "    x = Dense(512, activation=activation)(x)\n",
    "    x = LeakyReLU(alpha = 0.2)(x)\n",
    "    x = BatchNormalization(momentum = 0.8)(x)\n",
    "                                 \n",
    "    # output                            \n",
    "    img_label = Dense(np.prod(in_shape), activation='tanh')(x)\n",
    "\n",
    "    # Modelo del generador\n",
    "    generator_model = Model([gen_input, label], img_label)\n",
    "    \n",
    "    #plot_model(generator_model, to_file='cgan_generator_model.png', show_shapes=True)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    generator_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    return generator_model\n",
    "\n",
    "# Función para crear la cGAN\n",
    "def build_cgan(generator_model, discriminator_model,latent_dim,label_shape):\n",
    "    \n",
    "    # Congelar el discriminador durante el entrenamiento del generador\n",
    "    discriminator_model.trainable = False\n",
    "\n",
    "    # Entrada para la imagen de ruido\n",
    "    noise_input = Input(shape=(latent_dim,))\n",
    "    print(noise_input.shape)\n",
    "    # Entrada para la etiqueta\n",
    "    label_input = Input(shape=label_shape)\n",
    "    print(label_input.shape)\n",
    "    # Generar imagen a partir de la imagen de ruido y la etiqueta\n",
    "    img_output = generator_model([noise_input, label_input])\n",
    "    img_output = Reshape((28, 28, 1))(img_output)\n",
    "    print(img_output.shape)\n",
    "    # El discriminador se entrena para distinguir entre imágenes reales y falsas\n",
    "    validity = discriminator_model([img_output, label_input])\n",
    "\n",
    "    # Modelo de la cGAN\n",
    "    cgan_model = Model([noise_input, label_input], validity)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    optimizer = Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "    cgan_model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    return cgan_model\n",
    "\n",
    "\n",
    "\n",
    "# Crear los modelos\n",
    "discriminator = build_discriminator(in_shape, img_dim, 1)\n",
    "plot_model(discriminator, to_file='cgan_discriminator_2.png', show_shapes=True)\n",
    "discriminator.summary()\n",
    "\n",
    "generator     = build_generator(latent_dim, label_shape, in_shape)\n",
    "plot_model(generator, to_file='cgan_generator_2.png', show_shapes=True)\n",
    "generator.summary()\n",
    "\n",
    "cgan          = build_cgan(generator, discriminator,latent_dim,label_shape)\n",
    "plot_model(cgan, to_file='cgan_cgan_2.png', show_shapes=True)\n",
    "cgan.summary()\n",
    "\n",
    "def plot_images(generator, noise_input,  epoch):\n",
    "    # Generar imágenes a partir del ruido de entrada\n",
    " \n",
    "    rows, cols = 10, 10\n",
    "    noise  = np.random.normal(0, 1, (rows * cols, 100))\n",
    "    #labels = tf.keras.utils.to_categorical(np.random.randint(0, num_classes, rows * cols).reshape(-1, 1))  #y_train [:rows * cols]\n",
    "    labels =  np.random.randint(0, num_classes, rows * cols).reshape(-1, 1)\n",
    "    images = generator.predict([noise, labels])\n",
    "   \n",
    "    images = np.reshape(images, (images.shape[0], 28, 28, 1))\n",
    "    images = 0.5 * images + 0.5 # escalar de [-1,1] a [0,1]\n",
    "    images = np.uint8(255 * images) # escalar a [0, 255]\n",
    "    \n",
    "    #label_output = Lambda(lambda x: np.argmax(x, axis=1))(g_labels)\n",
    "    #label_output = tf.keras.utils.to_categorical(label_output, num_classes)\n",
    "    label_output = labels.ravel()\n",
    "    for i in range(rows):\n",
    "        row = images[i*cols:(i+1)*cols]\n",
    "        \n",
    "        row = np.concatenate(row, axis=1)\n",
    "        \n",
    "        plt.title(f'{label_output[i*cols:(i+1)*cols]}')\n",
    "        plt.imshow(row[:,:,0])\n",
    "        plt.axis('off')\n",
    "        #plt.title(f\"Epoch {epoch} - Row {i}\")\n",
    "        plt.tick_params(axis='both',labelsize=14)\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "def train(generator, discriminator, cgan, x_train, y_train, epochs, batch_size):\n",
    "    dd_losses = []\n",
    "    gg_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch: \", epoch)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Entrenamiento del Discriminador\n",
    "            # ---------------------\n",
    "\n",
    "            # Selecciona un conjunto aleatorio de imágenes reales\n",
    "        \n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "        real_images = x_train[idx]\n",
    "        real_labels = y_train[idx]\n",
    "           \n",
    "            # Genera un conjunto de imágenes falsas\n",
    "            \n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_labels = y_train[np.random.randint(0, y_train.shape[0], batch_size)] # np.random.randint(0, num_classes, batch_size)\n",
    "        \n",
    "        fake_images = generator.predict([noise, fake_labels])\n",
    "        fake_images = np.reshape(fake_images, (fake_images.shape[0], 28, 28, 1))\n",
    "        #label_output = Lambda(lambda x: np.argmax(x, axis=1))(gen_labels)\n",
    "        #label_output = tf.keras.utils.to_categorical(label_output, num_classes)\n",
    "        \n",
    "        label_output = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n",
    "            # Entrenar la red adversaria (discriminator)\n",
    "            \n",
    "        discriminator.trainable = True\n",
    "        discriminator_loss_real = discriminator.train_on_batch([real_images, real_labels], np.ones(batch_size))\n",
    "        discriminator_loss_fake = discriminator.train_on_batch([fake_images, label_output], np.zeros(batch_size))\n",
    "        d_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "    \n",
    "            # ---------------------\n",
    "            #  Entrenamiento del Generador\n",
    "            # ---------------------\n",
    "        discriminator.trainable = False\n",
    "            # Genera un conjunto de imágenes falsas\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_labels = y_train[np.random.randint(0,  y_train.shape[0], batch_size)]  #np.random.uniform(-1, 1, (batch_size, 1))\n",
    "        \n",
    "            # Etiquetas para la pérdida de la red generadora\n",
    "        y_generator = np.ones(batch_size)\n",
    "        g_loss = cgan.train_on_batch([noise,gen_labels], y_generator) #cgan.train_on_batch([noise, fake_labels], [np.ones(batch_size), fake_labels])\n",
    " \n",
    " \n",
    "        print(f\"Epoch: {epoch} \\t Discriminator Loss: {d_loss} \\t\\t Generator Loss: {g_loss}\")\n",
    "        dd_losses.append(d_loss)\n",
    "        gg_losses.append(g_loss)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            test_images = plot_images (generator,noise, epoch)\n",
    " \n",
    "    return [dd_losses, gg_losses,generator,discriminator,cgan]\n",
    "\n",
    "\n",
    "\n",
    "# Entrenamos el modelo\n",
    "epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "[dd_losses, gg_losses,generator,discriminator,cgan]  = train(generator, discriminator, cgan, X_train, y_train, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n6HYGh_N9br0"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.plot(DD_loss, label=\"Discriminator Loss\")\n",
    "plt.plot(GG_loss, label=\"Generator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que con 500 epocs ya sería suficiente para generar imagenes similares a las reales y no llega a detectar si son falsas o no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIgFpJ9jjvAq"
   },
   "source": [
    "### Ejercicio 2:\n",
    "Modifica el código para que use el dataset cifar10 en lugar del mnist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5tavpfcT9br0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rw0MyEi9br0"
   },
   "outputs": [],
   "source": [
    "# Visualizar imagenes-labels reales \n",
    "def show_real_img (real_img,real_label,class_names,num_classes):\n",
    "    # Vemos si se han cargado bien las imagenes\n",
    "    fig = plt.figure(figsize=(8,3))\n",
    "    for i in range(num_classes):\n",
    "        ax = plt.subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "        idx = np.where(real_label[:]==i)[0]\n",
    "        features_idx = real_img [idx,::]\n",
    "        img_num = np.random.randint(features_idx.shape[0])\n",
    "        img = features_idx[img_num,::]\n",
    "        ax.set_title(class_names[i])\n",
    "        plt.imshow(img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "# Visualizar imagenes-labels reales // imagenes-labels generaadas\n",
    "def generate_images(generator, epoch):\n",
    "    rows, cols = 10, 10\n",
    "    noise  = np.random.normal(0, 1, (rows * cols, 100))\n",
    "    labels = np.random.randint(0, num_classes, rows * cols).reshape(-1, 1)  #y_train [:rows * cols]\n",
    "    images = generator.predict([noise, labels])\n",
    "     \n",
    "    images = np.reshape(images, (images.shape[0], 32, 32, 3))\n",
    "    #images = 0.5 * images + 0.5 # escalar de [-1,1] a [0,1]\n",
    "    images = np.uint8(255 * images) # escalar a [0, 255]\n",
    "     \n",
    "    labels_in = labels.ravel()\n",
    "    \n",
    "    for i in range(rows):\n",
    "        row = images[i*cols:(i+1)*cols]\n",
    "        \n",
    "        row = np.concatenate(row, axis=1)\n",
    "        print (labels_in[i*cols:(i+1)*cols])\n",
    "        plt.title(f'{np.array(class_names)[labels_in[i*cols:(i+1)*cols]]}')\n",
    "        plt.imshow(row[:,:,0])\n",
    "        plt.axis('off')\n",
    "        #plt.title(f\"Epoch {epoch} - Row {i}\")\n",
    "        plt.tick_params(axis='both',labelsize=14)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "co0tC_pl9br0"
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# Datos para el modelo y el entrenamiento\n",
    "#----------------------------------------\n",
    "\n",
    "# Definir dimensiones de entrada\n",
    "in_shape =  (32, 32, 3)\n",
    "img_dim = np.prod (in_shape)\n",
    "init = initializers.RandomNormal(stddev=0.01)\n",
    "latent_dim = 100\n",
    " \n",
    "#optimizador\n",
    "OPTIMZADOR_ADAM = Adam(learning_rate=0.0003, beta_1=0.5)\n",
    "\n",
    "\n",
    "\n",
    "# Definir las variables relevantes\n",
    "# Datos\n",
    "# Load cifar10  \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog',\n",
    "                'frog','horse','ship','truck']\n",
    "\n",
    "# Visualizar imagenes cargadas del dataset\n",
    "show_real_img (X_train,y_train,class_names,num_classes)\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    " \n",
    "\n",
    "# Normalizamos a 0-255\n",
    "#X_train = X_train.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "print('X_train shape 2:', X_train.shape)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfoI3fdD9br0"
   },
   "outputs": [],
   "source": [
    " \n",
    "# ***********************************\n",
    "# Definir modelo generador\n",
    "# ***********************************\n",
    "generator = Sequential()\n",
    "\n",
    "# Input layer  \n",
    "generator.add(Dense(256, input_shape=(latent_dim,))) # , kernel_initializer=init\n",
    "generator.add(BatchNormalization( momentum=0.8)) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(Dense(128 )) # , kernel_initializer=init\n",
    "generator.add(BatchNormalization( momentum=0.8)) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(Dense(128 )) # , kernel_initializer=init\n",
    "generator.add(BatchNormalization( momentum=0.8)) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(Dense(64))\n",
    "generator.add(BatchNormalization()) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    " \n",
    "#generator.add(Dense(4096))\n",
    "#generator.add(LeakyReLU(alpha=0.2))\n",
    "#generator.add(BatchNormalization()) # momentum=0.8\n",
    " \n",
    "#generator.add(Dense(8192))\n",
    "#generator.add(LeakyReLU(alpha=0.2))\n",
    "#generator.add(BatchNormalization()) # momentum=0.8\n",
    "\n",
    "# Output layer\n",
    "#generator.add(Flatten())\n",
    "#generator.add(Dense(np.prod(in_shape), activation='sigmoid'))\n",
    "generator.add(Dense(np.prod(in_shape), activation='tanh'))\n",
    "generator.add(Reshape(in_shape))\n",
    "generator.summary()\n",
    "#generator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "\n",
    "plot_model(generator, to_file='gan_generator_cifar10.png', show_shapes=True)\n",
    "\n",
    "# ***********************************\n",
    "# Definir modelo discriminador\n",
    "# ***********************************\n",
    "\n",
    "# Discriminator network\n",
    "discriminator = Sequential()\n",
    "\n",
    "# Input layer  \n",
    "discriminator.add(Flatten(input_shape=in_shape))\n",
    "discriminator.add(Dense(64, input_shape=in_shape)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(128)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(128)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(256 )) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "discriminator.add(Dropout(0.3))\n",
    "# Output layer\n",
    " \n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "discriminator.summary()\n",
    "# Compilar modelos\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])\n",
    "\n",
    "plot_model(discriminator, to_file='gan_discriminator_cifar10.png', show_shapes=True)\n",
    "  \n",
    "#generator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    " \n",
    "# ***********************************\n",
    "# Definir modelo cGan\n",
    "# ***********************************\n",
    "\n",
    "  \n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(img)\n",
    "\n",
    "cGan = Model(z, validity)\n",
    "cGan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "cGan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUdaXbOk9br0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parámetros del entrenamiento\n",
    "\n",
    "epochs= 10000\n",
    "batch_size = 128\n",
    "sample_interval= 100\n",
    "\n",
    "# Bucle entrenamiento\n",
    "valid = np.ones((batch_size, 1))\n",
    "fake  = np.zeros((batch_size, 1))\n",
    "\n",
    "DD_loss = np.zeros((epochs,))\n",
    "GG_loss = np.zeros((epochs,))\n",
    "\n",
    "for cnt in range(epochs):\n",
    "    # ***********************************\n",
    "    # Paso 1: Entrenar el discriminador\n",
    "    discriminator.trainable = True\n",
    "    # ***********************************\n",
    "        \n",
    "    # Genera un conjunto de imágenes reales\n",
    "    idx = np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "\n",
    "    real_images = X_train [idx]\n",
    "    real_labels = y_train [idx]\n",
    "    \n",
    "    # Genera un conjunto de imágenes falsas\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "    fake_images = generator.predict(noise)\n",
    "    print ('fake_images:',fake_images.shape)\n",
    "    fake_images = np.reshape(fake_images, (fake_images.shape[0], 32, 32, 3))\n",
    "    \n",
    "    print ('real_images:',real_images.shape)\n",
    "    print ('valid:',valid.shape)\n",
    "    # Entrenamiento discriminador\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, valid)\n",
    "    d_loss_fake = discriminator.train_on_batch(fake_images, fake)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ***********************************\n",
    "    # Paso 2: Entrenar el generador\n",
    "    discriminator.trainable = False\n",
    "    # ***********************************\n",
    "    \n",
    "    gen_input  = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    g_loss = cGan.train_on_batch(gen_input,valid) \n",
    "\n",
    "    # ***********************************\n",
    "    # Paso 3: Evolución entrenamiento\n",
    "    # **********************************\n",
    "    DD_loss[cnt] = d_loss[0]\n",
    "    GG_loss[cnt] = g_loss\n",
    "    print ('epoch: %d/%d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, epochs, d_loss[0], g_loss))\n",
    "    # Mostrar el progreso del entrenamiento\n",
    "    if cnt % sample_interval == 0:\n",
    "              \n",
    "        # Visualizar imagenes cargadas del dataset\n",
    "        #r_img =  0.5 * real_images + 0.5\n",
    "        #r_img = (r_img* 255).astype(np.uint8)\n",
    "        \n",
    "        #show_real_img (r_img, real_labels, class_names, num_classes)\n",
    "        \n",
    "        # Generar imágenes de muestra\n",
    "        \n",
    "         # Generate images from the generator\n",
    "        r, c = 2, 5 # number of rows and columns of images to generate\n",
    "        noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        gen_imgs = (gen_imgs* 255).astype(np.uint8)\n",
    "    \n",
    "        # Plot generated images\n",
    "        fig, axs = plt.subplots(r, c,figsize=(6,3.9),dpi=100)\n",
    "        k = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[k, :,:,:])#.reshape(32, 32,3) )#.reshape(32, 32,3)\n",
    "                axs[i,j].axis('off')\n",
    "                k += 1\n",
    "        plt.show()\n",
    "#axs[i, j].imshow(gen_imgs[k,:,:,0].reshape(32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcYZuzzP9br1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.plot(DD_loss, label=\"Discriminator Loss\")\n",
    "plt.plot(GG_loss, label=\"Generator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "un modelo malo. noo llega a converger. El generador no llega a interpretar y generar imagenes correctas y e disriminador en todo momento sabe si una imagen es real o falsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar imágenes con etiquetas aleatorias\n",
    "n_to_show   = 10\n",
    "latent_dim  = 100\n",
    "num_classes = 10\n",
    "\n",
    "z = np.random.normal(loc=0, scale=1, size=(n_to_show, latent_dim))\n",
    "x_fake = generator.predict(z)\n",
    "x_fake =  np.reshape(x_fake, (x_fake.shape[0], 32, 32, 3))\n",
    "x_fake = 0.5 * x_fake + 0.5 # escalar de [-1,1] a [0,1]\n",
    "x_fake = np.uint8(255 * x_fake).astype(np.uint8) # escalar a [0, 255]\n",
    "\n",
    "# Mostrar imágenes generadas con sus etiquetas\n",
    "fig, axs = plt.subplots(1, n_to_show, figsize=(20,6.9),dpi=100)\n",
    "for i in range(n_to_show):\n",
    "    axs[i].imshow(x_fake[i, :,:])\n",
    "    axs[i].axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 .-  Cambiamos la red, compilamos la arquitectura del modelo y entrenamos de otra forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ***********************************\n",
    "# Definir modelo generador\n",
    "# ***********************************\n",
    "#optimizador\n",
    "OPTIMZADOR_ADAM = Adam(learning_rate=0.003, beta_1=0.5,beta_2=0.99)\n",
    "\n",
    "generator = Sequential()\n",
    "\n",
    "# Input layer  \n",
    "generator.add(Dense (256, input_shape=(latent_dim,))) # , kernel_initializer=init\n",
    "generator.add(LeakyReLU (alpha=0.2))\n",
    "generator.add(BatchNormalization (momentum=0.8)) # momentum=0.8\n",
    "generator.add(Dropout(0.3))\n",
    "\n",
    "generator.add(Dense (512 )) # , kernel_initializer=init\n",
    "generator.add(LeakyReLU (alpha=0.2))\n",
    "generator.add(BatchNormalization (momentum=0.8)) # momentum=0.8\n",
    "generator.add(Dropout(0.3))\n",
    " \n",
    "generator.add(Dense (1024 )) # , kernel_initializer=init\n",
    "generator.add(LeakyReLU (alpha=0.2))\n",
    "generator.add(BatchNormalization (momentum=0.8)) # momentum=0.8\n",
    "generator.add(Dropout(0.3))\n",
    "\n",
    "#generator.add(Dense(2048))\n",
    "#generator.add(LeakyReLU(alpha=0.2))\n",
    "#generator.add(BatchNormalization(momentum=0.8)) # momentum=0.8\n",
    "#generator.add(Dropout(0.3))\n",
    "\n",
    "#generator.add(Dense(4096))\n",
    "#generator.add(LeakyReLU(alpha=0.2))\n",
    "#generator.add(BatchNormalization()) # momentum=0.8\n",
    "#generator.add(Dropout(0.3))\n",
    "\n",
    "#generator.add(Dense(8192))\n",
    "#generator.add(LeakyReLU(alpha=0.2))\n",
    "#generator.add(BatchNormalization()) # momentum=0.8\n",
    "#generator.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "#generator.add(Dense(np.prod(in_shape), activation='sigmoid'))\n",
    "generator.add (Dense(np.prod (in_shape), activation='tanh'))\n",
    "generator.add (Reshape (in_shape))\n",
    "generator.summary ()\n",
    "\n",
    "#generator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "#plot_model(generator, to_file='gan_generator_cifar10.png', show_shapes=True)\n",
    "\n",
    "# ***********************************\n",
    "# Definir modelo discriminador\n",
    "# ***********************************\n",
    "\n",
    "# Discriminator network\n",
    "discriminator = Sequential()\n",
    "\n",
    "# Input layer  \n",
    "discriminator.add(Flatten(input_shape=in_shape))\n",
    "\n",
    "discriminator.add(Dense(512, input_shape=in_shape )) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "\n",
    "discriminator.add(Dense(256)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "\n",
    "discriminator.add(Dense(128)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "\n",
    "#discriminator.add(Dense(64 )) # , kernel_initializer=init\n",
    "#discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "\n",
    "#discriminator.add(Dense(32 )) # , kernel_initializer=init\n",
    "#discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "\n",
    "# Output layer\n",
    " \n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    " \n",
    "discriminator.summary()\n",
    "# Compilar modelos\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])\n",
    "\n",
    "plot_model(discriminator, to_file='gan_discriminator_cifar10.png', show_shapes=True)\n",
    "  \n",
    "#generator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    " \n",
    "# ***********************************\n",
    "# Definir modelo cGan\n",
    "# ***********************************\n",
    "\n",
    "  \n",
    "z = Input(shape=(latent_dim,))\n",
    "img = generator(z)\n",
    "\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(img)\n",
    "\n",
    "cGan = Model(z, validity)\n",
    "cGan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.002, beta_1=0.5))\n",
    "cGan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "smooth = 0.1\n",
    "\n",
    "real = np.ones(shape=(batch_size, 1))\n",
    "fake = np.zeros(shape=(batch_size, 1))\n",
    "\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "\n",
    "for e in range(epochs + 1):\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        \n",
    "        # Train Discriminator weights\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Real samples\n",
    "        X_batch = X_train[i*batch_size:(i+1)*batch_size]\n",
    "        d_loss_real = discriminator.train_on_batch(x=X_batch,\n",
    "                                                   y=real * (1 - smooth))\n",
    "        \n",
    "        # Fake Samples\n",
    "        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n",
    "        X_fake = generator.predict_on_batch(z)\n",
    "        d_loss_fake = discriminator.train_on_batch(x=X_fake, y=fake)\n",
    "         \n",
    "        # Discriminator loss\n",
    "        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "        \n",
    "        # Train Generator weights\n",
    "        discriminator.trainable = False\n",
    "        g_loss_batch = cGan.train_on_batch(x=z, y=real)\n",
    "\n",
    "        print('epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, g_loss_batch),100*' ')\n",
    "    \n",
    "    d_loss.append(d_loss_batch)\n",
    "    g_loss.append(g_loss_batch)\n",
    "    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], g_loss[-1]), 100*' ')\n",
    "\n",
    "    #if e % 10 == 0:\n",
    "    samples = 10\n",
    "    x_fake = generator.predict(np.random.normal(loc=0, scale=1, size=(samples, latent_dim)))\n",
    "\n",
    "    for k in range(samples):\n",
    "        plt.subplot(2, 5, k + 1, xticks=[], yticks=[])\n",
    "        plt.imshow(((x_fake[k] + 1)* 127).astype(np.uint8))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.plot(d_loss, label=\"Discriminator Loss\")\n",
    "plt.plot(g_loss, label=\"Generator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnPWq7oH9br1"
   },
   "outputs": [],
   "source": [
    "# Generar imágenes con etiquetas aleatorias\n",
    "n_to_show   = 10\n",
    "latent_dim  = 100\n",
    "num_classes = 10\n",
    "\n",
    "z = np.random.normal(loc=0, scale=1, size=(n_to_show, latent_dim))\n",
    "x_fake = generator.predict(z)\n",
    "x_fake =  np.reshape(x_fake, (x_fake.shape[0], 32, 32, 3))\n",
    "x_fake = 0.5 * x_fake + 0.5 # escalar de [-1,1] a [0,1]\n",
    "x_fake = np.uint8(255 * x_fake).astype(np.uint8) # escalar a [0, 255]\n",
    "\n",
    "# Mostrar imágenes generadas con sus etiquetas\n",
    "fig, axs = plt.subplots(1, n_to_show, figsize=(20,6.9),dpi=100)\n",
    "for i in range(n_to_show):\n",
    "    axs[i].set_title(f'Label: {class_names[i]}')\n",
    "    axs[i].imshow(x_fake[i, :,:])\n",
    "    axs[i].axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos peores resultados. Vemos que en este caso, con imagenes algo más complejas, utilizar exclusivamente capas lineales densas nos lleva a resultados no deseados. Probablemente habría que optimzar más los hiperparámetros y/o realizar mas emtrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "achQWoMJk9WK"
   },
   "source": [
    "### Ejercicio 3:\n",
    "Modifica el código para que use capas convolucionales en lugar de densas (en la medida de lo posible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWZaMcz-9br1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout,Conv2DTranspose,Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from keras.models import Sequential, Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from IPython.core.debugger import Tracer\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0YObv1h9br1"
   },
   "outputs": [],
   "source": [
    "# Visualizar imagenes reales \n",
    "def show_real_img (real_img):\n",
    "    # Vemos si se han cargado bien las imagenes\n",
    "    fig = plt.figure(figsize=(2,5))\n",
    "    for i in range(10):\n",
    "        ax = plt.subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "        features_idx = real_img [i,::]\n",
    "        plt.imshow(features_idx)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "# Datos\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KhsY0uX9br1"
   },
   "outputs": [],
   "source": [
    "# Definir la forma de entrada\n",
    "width    = 28\n",
    "height   = 28\n",
    "channels = 1\n",
    "in_shape = (width, height, channels)\n",
    "# imagem dimension 28x28\n",
    "img_dim    = np.prod( in_shape)\n",
    "latent_dim = 100\n",
    "init = initializers.RandomNormal (stddev=0.02)\n",
    "# Definir el optimizador\n",
    "OPTIMZADOR_ADAM = Adam (learning_rate = 0.002, beta_1 =0.5)#, beta_1=0.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tL2ycd9w9br1",
    "outputId": "1449fd6f-962b-4388-86af-a590f15b9bae"
   },
   "outputs": [],
   "source": [
    "def build_generator_1(latent_dim, in_shape, img_dim, init, channels = 1,\n",
    "                      kernel_size = (5, 5), strides = (1, 1), padding='same', \n",
    "                      use_bias = False):\n",
    "    \n",
    "    generator = Sequential ()\n",
    "\n",
    "    generator.add (Dense(256*7*7, input_shape = (latent_dim,), \n",
    "                                     kernel_initializer = init))\n",
    "    generator.add (BatchNormalization())\n",
    "    generator.add (LeakyReLU())\n",
    "    \n",
    "    generator.add (Reshape((7,7,256)))\n",
    "    \n",
    "\n",
    "    generator.add(Conv2DTranspose(filters = 128, kernel_size = kernel_size, \n",
    "                                  strides = strides, padding = padding, use_bias = use_bias))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU())\n",
    "    \n",
    "    generator.add(Conv2DTranspose(filters = 64, kernel_size = kernel_size, \n",
    "                                  strides =(strides [0]*2, strides [1]*2), padding = padding, use_bias = use_bias))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU())\n",
    "\n",
    "    generator.add(Conv2DTranspose(filters=channels, kernel_size=kernel_size, \n",
    "                                  strides=(strides [0]*2, strides [1]*2), use_bias = use_bias,  padding=padding, activation='tanh'))\n",
    "\n",
    "\n",
    "\n",
    "    return generator\n",
    "\n",
    "#++++++++++++++++++++++++++++++++++++++++++++\n",
    "#++++++++++++++++++++++++++++++++++++++++++++\n",
    "#++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "def build_generator_2 (latent_dim,in_shape, img_dim, init, channels = 1,\n",
    "                       kernel_size = 3, strides = (1, 1), padding='same', \n",
    "                       use_bias = False):\n",
    "    \n",
    "    generator = tf.keras.Sequential ()\n",
    "    generator.add(Dense (7*7*256, use_bias = use_bias, input_shape = (latent_dim,), \n",
    "                                     kernel_initializer = init))\n",
    "    generator.add(BatchNormalization (momentum = 0.8 ))\n",
    "    generator.add(LeakyReLU (0.2))\n",
    "    generator.add(Reshape ((7, 7, 256)))\n",
    "\n",
    "    generator.add(Conv2DTranspose (128, kernel_size = kernel_size, \n",
    "                                      strides = strides, padding = padding, use_bias = use_bias))\n",
    "    generator.add(BatchNormalization (momentum = 0.8 ))\n",
    "    generator.add(LeakyReLU (0.2))\n",
    "\n",
    "    generator.add(Conv2DTranspose (64, kernel_size = kernel_size, strides = (strides [0]*2, strides [1]*2), \n",
    "                                          padding = padding, use_bias = use_bias))\n",
    "    generator.add(BatchNormalization (momentum = 0.8 ))\n",
    "    generator.add(LeakyReLU (0.2))\n",
    "\n",
    "    generator.add(Conv2DTranspose (channels, kernel_size = kernel_size, \n",
    "                                      strides = (strides [0]*2, strides [1]*2), padding = padding, use_bias = use_bias, activation = 'tanh'))\n",
    " \n",
    "    generator_input  = Input(shape = (latent_dim,))\n",
    "    generator_output = generator (generator_input)\n",
    "\n",
    "    generator_model  = Model(generator_input, generator_output)\n",
    "    return generator_model\n",
    "\n",
    "# Definir el generador\n",
    "#generator =  build_generator_1  (latent_dim, in_shape, img_dim, init, channels = 1, kernel_size = (5, 5), \n",
    "#                                strides = (1, 1), padding = 'same', use_bias = False)\n",
    "generator =  build_generator_2 (latent_dim, in_shape, img_dim, init, channels = 1, kernel_size = 3, \n",
    "                                strides = (1, 1), padding = 'same', use_bias = False)\n",
    "generator.summary()\n",
    "generator.compile(loss='binary_crossentropy', optimizer = OPTIMZADOR_ADAM, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpcN57uc9br1",
    "outputId": "889995f8-2357-4fda-af4b-596031272ebc"
   },
   "outputs": [],
   "source": [
    "\n",
    "def build_discriminator_1(latent_dim,in_shape, img_dim, channels = 1, \n",
    "                          kernel_size = (5, 5), strides = (2,2), padding = 'same'):\n",
    "    discriminator  = Sequential ()\n",
    "\n",
    "    discriminator.add (Conv2D (filters = 64, kernel_size = kernel_size, strides = strides,\n",
    "                               padding = padding, input_shape=in_shape))\n",
    "    #discriminator.add(BatchNormalization()) # momentum=0.8                   \n",
    "    discriminator.add (LeakyReLU ())\n",
    "    discriminator.add(layers.Dropout (0.3))                   \n",
    "\n",
    "    discriminator.add (Conv2D (filters=128, kernel_size = kernel_size, strides = strides, \n",
    "                             padding = padding))\n",
    "    #discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "    discriminator.add(LeakyReLU())\n",
    "    discriminator.add(Dropout(0.3))\n",
    "\n",
    "    discriminator.add(Flatten())\n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_discriminator_2 (latent_dim,in_shape, img_dim,  init, channels = 1,\n",
    "                          kernel_size=3, strides = (1, 1), padding= 'same'):\n",
    "                       \n",
    "    discriminator  = Sequential ()\n",
    "\n",
    "    discriminator.add (Conv2D(filters=64, kernel_size=kernel_size, strides = strides, padding = padding,\n",
    "                          input_shape = in_shape, kernel_initializer = init))\n",
    "    discriminator.add (BatchNormalization (momentum=0.8 ))#\n",
    "    discriminator.add (LeakyReLU (alpha = 0.2))\n",
    "    discriminator.add (Dropout (0.3))\n",
    "    \n",
    "    discriminator.add (Conv2D (filters=128, kernel_size = kernel_size, strides = strides, padding = padding,\n",
    "                              kernel_initializer = init))\n",
    "    discriminator.add (BatchNormalization (momentum=0.8))#momentum=0.8\n",
    "    discriminator.add (LeakyReLU(alpha = 0.2))\n",
    "    discriminator.add (Dropout (0.3))\n",
    "    \n",
    "    discriminator.add (Conv2D(filters=256, kernel_size = kernel_size, strides = strides, padding = padding,\n",
    "                            kernel_initializer = init))\n",
    "    discriminator.add (BatchNormalization (momentum=0.8 ))#momentum=0.8\n",
    "    discriminator.add (LeakyReLU (alpha = 0.2))\n",
    "    discriminator.add (Dropout (0.3))\n",
    "\n",
    "    discriminator.add (Flatten ())\n",
    "    discriminator.add (Dense (channels, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "################################################\n",
    "# Definir el discriminador\n",
    "################################################´\n",
    "\n",
    "#discriminator = build_discriminator_1 (latent_dim,in_shape, img_dim, channels= 1,   kernel_size = (5, 5), strides = (1, 1),   padding= 'same')\n",
    "discriminator = build_discriminator_2 (latent_dim,in_shape, img_dim,  init, channels = 1, kernel_size = 3, strides = (2,2), padding='same')\n",
    "discriminator.summary()\n",
    "\n",
    "# Compilar el discriminador\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JvhxN2k-9br2",
    "outputId": "f0e7e6df-de13-4df2-bf8b-39e9e3247000"
   },
   "outputs": [],
   "source": [
    "# Combinar el generador y el discriminador\n",
    "model_gan = Sequential()\n",
    "model_gan.add(generator)\n",
    "model_gan.add(discriminator)\n",
    "\n",
    "# Compilar el GAN\n",
    "model_gan.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "model_gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir el número de épocas y el tamaño del lote\n",
    "num_epochs = 3000\n",
    "batch_size = 128\n",
    "sample_interval = 100\n",
    "num_classes = 10\n",
    "# Definir los vectores de seguimiento para la pérdida del generador y del discriminador\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "c_ones  = np.ones((batch_size, 1))\n",
    "c_zeros = np.zeros((batch_size, 1))\n",
    "# Entrenar el modelo\n",
    "for epoch in range(num_epochs):\n",
    "    discriminator.train = True\n",
    "    # Seleccionar un conjunto aleatorio de imágenes de entrenamiento reales\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    real_images = X_train[idx]\n",
    "    #show_real_img (real_images)\n",
    "    # Generar un conjunto aleatorio de imágenes de entrenamiento falsas\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    noise = (noise - 0.5) * 2 # escalar los valores al rango de -1 a 1\n",
    "    fake_images = generator.predict(noise)\n",
    "\n",
    "    # Entrenar el discriminador en las imágenes reales y falsas\n",
    "    d_loss_real = discriminator.train_on_batch(real_images, c_ones)\n",
    "    d_loss_fake = discriminator.train_on_batch(fake_images, c_zeros)\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "    discriminator.train = False\n",
    "    # Entrenar el generador para engañar al discriminador\n",
    "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    noise = (noise - 0.5) * 2\n",
    "    g_loss = model_gan.train_on_batch(noise, c_ones)\n",
    "    \n",
    "    # Guardar el seguimiento de las pérdidas del generador y del discriminador\n",
    "    losses_g.append (g_loss)\n",
    "    losses_d.append (d_loss[0])\n",
    "    \n",
    "    # Imprimir el progreso del entrenamiento\n",
    "    print(\"Epoca: %d [Discriminador Loss: %f] [Generador Loss: %f]\" % (epoch, d_loss[0], g_loss ))\n",
    "    if epoch % sample_interval == 0:\n",
    "\n",
    "        # Generar imágenes falsas a partir de vectores de ruido aleatorios\n",
    "        noise = np.random.normal(0, 1, (num_classes, latent_dim))\n",
    "        noise = (noise - 0.5) * 2\n",
    "        images = generator.predict(noise)\n",
    " \n",
    "             \n",
    "        images = 0.5 * images + 0.5 # escalar de [-1,1] a [0,1]\n",
    "        #images = np.uint8(255 * images) # escalar a [0, 255]\n",
    "        # Mostrar las imágenes generadas\n",
    "        r = 2\n",
    "        c = 5\n",
    "        fig, axs = plt.subplots(r, c,figsize=(11,6.9),dpi=100)\n",
    "        count = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(images[count, :, :].reshape(28,28), cmap=\"gray\") #, cmap='gray'\n",
    "                axs[i,j].axis('off')\n",
    "                count += 1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.figure\n",
    "plt.plot (losses_g, label=\"Generator Loss\")\n",
    "plt.plot (losses_d, label=\"Discriminator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los números son más nitidos que en la red donde se utilizan sólo capas densas. y con esta configuracón de hiperparámetros y arquitectura d capsa se necesitan pocas epochs para conseguir un resultado aceptable. Asemás vemos que con unos 900 y 100 epochs el modelo converge, teniendo unos errores aprox. constantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgjFQwT_9br3"
   },
   "source": [
    "# otro: Veamos con imagenes más complejas (Cifar-10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RE7JBGH_9br3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LeakyReLU, BatchNormalization, ReLU\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "from keras.utils import plot_model, np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IsEFzQYV9br4"
   },
   "outputs": [],
   "source": [
    " # load dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(0, 10):\n",
    "    plt.subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    plt.imshow(X_train[i])\n",
    "    \n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(num_classes):\n",
    "    ax = plt.subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:]==i)[0]\n",
    "    features_idx = X_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    img = features_idx[img_num,::]\n",
    "    ax.set_title(class_names[i])\n",
    "    plt.imshow(img)\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape (X_train.shape [0], 3, 32, 32)\n",
    "    X_test  = X_test.reshape (X_test.shape [0], 3, 32, 32)\n",
    "    input_shape = (3, 32, 32)\n",
    "else:\n",
    "    X_train = X_train.reshape (X_train.shape [0], 32, 32, 3)\n",
    "    X_test  = X_test.reshape (X_test.shape [0], 32, 32, 3)\n",
    "    input_shape = (32, 32, 3)\n",
    "    \n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical (y_train, num_classes)\n",
    "Y_test  = np_utils.to_categorical (y_test, num_classes)\n",
    "\n",
    "# the generator is using tanh activation, for which we need to preprocess \n",
    "# the image data into the range between -1 and 1.\n",
    "\n",
    "X_train = np.float32(X_train)\n",
    "X_train = (X_train / 255 - 0.5) * 2\n",
    "X_train = np.clip(X_train, -1, 1)\n",
    "\n",
    "X_test = np.float32(X_test)\n",
    "X_test = (X_train / 255 - 0.5) * 2\n",
    "X_test = np.clip(X_test, -1, 1)\n",
    "\n",
    "print('X_train reshape:', X_train.shape)\n",
    "print('X_test reshape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space dimension\n",
    "latent_dim = 100\n",
    "\n",
    "init = initializers.RandomNormal (stddev = 0.02)\n",
    "\n",
    "# Generator network\n",
    "generator = Sequential()\n",
    "\n",
    "# FC: 2x2x512\n",
    "generator.add (Dense (4*4*512, input_shape = (latent_dim,)))# , kernel_initializer=init\n",
    "generator.add (LeakyReLU (alpha = 0.2)) ## ReLU()\n",
    "generator.add (Reshape ((4, 4, 512)))\n",
    "#generator.add (BatchNormalization ())\n",
    "\n",
    "\n",
    "# # Conv 1: 4x4x256\n",
    "generator.add (Conv2DTranspose (128, kernel_size = 4, strides = 2, padding='same'))\n",
    "#generator.add(BatchNormalization())\n",
    "generator.add (LeakyReLU (alpha = 0.2))## ReLU() \n",
    "\n",
    "# Conv 2: 8x8x128\n",
    "generator.add (Conv2DTranspose (128, kernel_size = 4, strides = 2, padding='same'))\n",
    "#generator.add(BatchNormalization())\n",
    "generator.add (LeakyReLU (alpha = 0.2))## ReLU() alpha = 0.2\n",
    "\n",
    "# Conv 3: 16x16x64\n",
    "#generator.add (Conv2DTranspose (128, kernel_size = 5, strides = 2, padding = 'same'))\n",
    "#generator.add(BatchNormalization())\n",
    "#generator.add (ReLU ( ))##LeakyReLU(0.2)\n",
    "\n",
    "# Conv 4: 32x32x3\n",
    "generator.add  (Conv2DTranspose (3, kernel_size = 3, strides = 2, padding = 'same',\n",
    "                              activation = 'tanh'))\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imagem shape 32x32x3\n",
    "img_shape = X_train[0].shape\n",
    "\n",
    "# Discriminator network\n",
    "discriminator = Sequential ()\n",
    "# Conv 0:  32x32x3\n",
    "discriminator.add (Conv2D (64, kernel_size = 3, strides = 2, padding = 'same',\n",
    "                                                  input_shape = (img_shape))) #\n",
    "discriminator.add (LeakyReLU (alpha = 0.2))\n",
    "\n",
    "# Conv 1: 16x16x64\n",
    "discriminator.add (Conv2D (128, kernel_size = 3, strides = 2, padding = 'same')) #input_shape=(img_shape), kernel_initializer=init\n",
    "#discriminator.add BatchNormalization ())\n",
    "discriminator.add (LeakyReLU (alpha = 0.2))#0.2\n",
    "# discriminator.add(Dropout(0.4))\n",
    "\n",
    "# Conv 2: 8x8x128\n",
    "discriminator.add (Conv2D (128, kernel_size = 3, strides = 2, padding = 'same'))\n",
    "#discriminator.add BatchNormalization ())\n",
    "discriminator.add (LeakyReLU (alpha = 0.2))#0.2\n",
    " \n",
    "\n",
    "# Conv 3: 4x4x256\n",
    "discriminator.add (Conv2D (256, kernel_size = 3, strides = 2, padding = 'same'))\n",
    "#discriminator.add(BatchNormalization())\n",
    "discriminator.add (LeakyReLU (alpha = 0.2 ))#0.2\n",
    "\n",
    " \n",
    "\n",
    "# FC: 2048\n",
    "discriminator.add (Flatten ())\n",
    "discriminator.add (Dropout (0.4))\n",
    "# Output: 1\n",
    "discriminator.add (Dense (1, activation='sigmoid'))\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "discriminator.compile (Adam (learning_rate = 0.0002, beta_1 = 0.5), loss = 'binary_crossentropy',\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_g = discriminador(generador(z))\n",
    "discriminator.trainable = False\n",
    "\n",
    "z   = Input (shape = (latent_dim,))\n",
    "img = generator (z)\n",
    "decision = discriminator (img)\n",
    "d_g = Model (inputs = z, outputs = decision)\n",
    "\n",
    "d_g.compile (Adam (learning_rate = 0.0004, beta_1 = 0.5), loss = 'binary_crossentropy',\n",
    "            metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "smooth = 0.1\n",
    "\n",
    "real = np.ones (shape = (batch_size, 1))\n",
    "fake = np.zeros (shape = (batch_size, 1))\n",
    "\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "\n",
    "for e in range (epochs + 1):\n",
    "    for i in range (len (X_train) // batch_size):\n",
    "        \n",
    "        # Train Discriminator weights\n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        # Real samples\n",
    "        X_batch = X_train [i*batch_size:(i+1)*batch_size]\n",
    "        d_loss_real = discriminator.train_on_batch (x = X_batch, y = real * (1 - smooth))\n",
    "        \n",
    "        # Fake Samples\n",
    "        z = np.random.normal (loc = 0, scale = 1, size = (batch_size, latent_dim))\n",
    "        X_fake = generator.predict_on_batch (z)\n",
    "        d_loss_fake = discriminator.train_on_batch(x=X_fake, y=fake)\n",
    "         \n",
    "        # Discriminator loss\n",
    "        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n",
    "        \n",
    "        # Train Generator weights\n",
    "        discriminator.trainable = False\n",
    "        g_loss_batch = d_g.train_on_batch (x=z, y=real)\n",
    "\n",
    "        print(\n",
    "            'epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, g_loss_batch[0]),\n",
    "            100*' ',\n",
    "            end='\\r'\n",
    "        )\n",
    "    \n",
    "    d_loss.append (d_loss_batch)\n",
    "    g_loss.append (g_loss_batch [0])\n",
    "    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], g_loss[-1]), 100*' ')\n",
    "\n",
    "    if e % 2 == 0:\n",
    "        samples = 10\n",
    "        x_fake = generator.predict (np.random.normal (loc = 0, scale = 1, size = (samples, latent_dim)))\n",
    "\n",
    "        for k in range (samples):\n",
    "            plt.subplot (2, 5, k + 1, xticks=[], yticks=[])\n",
    "            plt.imshow (((x_fake[k] + 1)* 127).astype (np.uint8))\n",
    "\n",
    "        plt.tight_layout ()\n",
    "        plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%matplotlib inline \n",
    "plt.figure ()\n",
    "plt.plot (g_loss, label=\"Generator Loss\")\n",
    "plt.plot (d_loss, label=\"Discriminator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Generar imágenes con etiquetas aleatorias\n",
    "n_to_show   = 10\n",
    "latent_dim  = 100\n",
    "num_classes = 10\n",
    "\n",
    "z = np.random.normal(loc=0, scale=1, size=(n_to_show, latent_dim))\n",
    "x_fake = generator.predict(z)\n",
    "x_fake =  np.reshape(x_fake, (x_fake.shape[0], 32, 32, 3))\n",
    "x_fake = 0.5 * x_fake + 0.5 # escalar de [-1,1] a [0,1]\n",
    "x_fake = np.uint8(255 * x_fake).astype(np.uint8) # escalar a [0, 255]\n",
    "\n",
    "# Mostrar imágenes generadas con sus etiquetas\n",
    "fig, axs = plt.subplots(1, n_to_show, figsize=(20,6.9),dpi=100)\n",
    "for i in range(n_to_show):\n",
    "    axs[i].imshow(x_fake[i, :,:])\n",
    "    axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
