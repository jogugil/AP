{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2Ubr-O3iQVy"
   },
   "source": [
    "# **Práctica 3**: GANs\n",
    "# Parte 1-2: GANs simples - Ejercicios Exttas\n",
    "\n",
    "Simplificación de:\n",
    "https://medium.com/@mattiaspinelli/simple-generative-adversarial-network-gans-with-keras-1fe578e44a87\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVvKu0703LIr"
   },
   "source": [
    "### Ejercicio EXTRA:\n",
    "Modifica el código para balancear cuanto aprende el generador y cuanto el discriminador.\n",
    "\n",
    "Por ejemplo haz que el número de datos en el batch de entrenamiento dependa del coste (loss) en el paso de entrenamiento anterior de cada modelo (generador o discriminador). Es decir, si el discriminador aprende mucho (su loss es bajo) en el siguiente paso de entrenamiento le daré menos datos (opara que aprenda menos).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACGmruV3AyAA"
   },
   "source": [
    "1. Definimos las variables \"gen_batch_size\" y \"disc_batch_size\" que serán las que determinen el tamaño del batch de cada modelo en cada iteración del bucle de entrenamiento. Establecemos su valor inicial en \"batch\", el tamaño de batch original.\n",
    "\n",
    "3. En cada iteración del bucle de entrenamiento, calculamos el coste (loss) de cada modelo en la iteración anterior y lo almacenamos en las variables \"d_loss_prev\" y \"g_loss_prev\".\n",
    "\n",
    "3. Para el discriminador, comparamos su coste anterior con el coste actual y, si ha mejorado, reducimos el tamaño del batch en un 10%, mientras que si ha empeorado, lo aumentamos en un 10%. En cualquier caso, aseguramos que el tamaño mínimo del batch sea 1.\n",
    "\n",
    "4. Para el generador, hacemos lo mismo que para el discriminador pero con la inversa, es decir, si ha mejorado aumentamos el tamaño del batch y si ha empeorado lo reducimos.\n",
    "\n",
    "5. Utilizamos los tamaños de batch calculados para entrenar los modelos en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q74B1d6ajuPu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#from IPython.core.debugger import Tracer\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD65a9bX3LIs"
   },
   "outputs": [],
   "source": [
    "#tf.config.run_functions_eagerly(True)\n",
    "# Set random seed\n",
    "#tf.random.set_seed (42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PlWIOF1N9br4"
   },
   "outputs": [],
   "source": [
    "# Datos\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FycwbaUYBU_g"
   },
   "outputs": [],
   "source": [
    "width=28\n",
    "height=28\n",
    "channels=1\n",
    "\n",
    "in_shape = X_train.shape\n",
    "in_shape = in_shape[1:]\n",
    "OPTIMZADOR_ADAM = Adam(learning_rate=0.0002, beta_1=0.5, decay=8e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNkg5PcB9br4",
    "outputId": "cc3bd785-8515-4e8c-c0d9-99d1fd27e713"
   },
   "outputs": [],
   "source": [
    "model_gen = Sequential()\n",
    "model_gen.add (Dense (256, input_shape = (100,)))\n",
    "model_gen.add (LeakyReLU (alpha = 0.2))\n",
    "model_gen.add (BatchNormalization (momentum = 0.8))\n",
    "model_gen.add (Dense (512))\n",
    "model_gen.add (LeakyReLU (alpha = 0.2))\n",
    "model_gen.add (BatchNormalization (momentum = 0.8))\n",
    "model_gen.add (Dense(1024))\n",
    "model_gen.add (LeakyReLU (alpha=0.2))\n",
    "model_gen.add (BatchNormalization (momentum = 0.8))\n",
    "model_gen.add (Dense (np.prod (in_shape), activation = 'tanh'))\n",
    "model_gen.add (Reshape (in_shape))\n",
    "model_gen.summary ()\n",
    "model_gen.compile (loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "\n",
    "model_Disc = Sequential ()\n",
    "model_Disc.add (Flatten(input_shape = in_shape))\n",
    "model_Disc.add (Dense(128, input_shape = in_shape))\n",
    "model_Disc.add (LeakyReLU(alpha = 0.2))\n",
    "model_Disc.add (Dense(64))\n",
    "model_Disc.add (LeakyReLU(alpha = 0.2))\n",
    "model_Disc.add (Dense(1, activation = 'sigmoid'))\n",
    " \n",
    "model_Disc.compile (loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics = ['accuracy'])\n",
    "\n",
    "model_gan = Sequential()\n",
    "model_gan.add (model_gen)\n",
    "model_gan.add (model_Disc)\n",
    "model_gan.compile (loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, run_eagerly = True)\n",
    "\n",
    "\n",
    "model_gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVvR3O9YBBSw",
    "outputId": "b68dcec6-2f20-4f96-cab3-c075ade1a1e8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parámetros del entrenamiento\n",
    "epochs = 5000\n",
    "batch = 10\n",
    "gen_batch_size  = batch\n",
    "disc_batch_size = batch/2\n",
    "\n",
    "sample_interval = 100\n",
    "num_classes     = 10\n",
    "latent_dim      = 100\n",
    "d_loss_prev     = np.inf\n",
    "g_loss_prev     = np.inf\n",
    "\n",
    "DD_loss = np.zeros((epochs,))\n",
    "GG_loss = np.zeros((epochs,))\n",
    "\n",
    "\n",
    "for cnt in range(epochs):\n",
    "\n",
    "    ## Entrenamos discriminador\n",
    "        # Imágenes reales\n",
    "    random_index = np.random.randint(0, len(X_train) - np.int64(disc_batch_size))\n",
    "    legit_images = X_train[random_index : random_index + np.int64(disc_batch_size)].reshape((np.int64(disc_batch_size),)+in_shape)\n",
    "        # Imágenes sintéticas\n",
    "    gen_noise = np.random.normal(0, 1, (np.int64(disc_batch_size), 100))\n",
    "    print('gen_noise:',gen_noise.shape)\n",
    "    syntetic_images = model_gen.predict(gen_noise)\n",
    "        # Combinamos imágenes reales y sintéticas\n",
    "    x_combined_batch = np.concatenate((legit_images, syntetic_images))\n",
    "    y_combined_batch = np.concatenate((np.ones((np.int64(disc_batch_size), 1)), np.zeros((np.int64(disc_batch_size), 1))))\n",
    "        # Entrenamos discriminador\n",
    "    d_loss = model_Disc.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "   \n",
    "    # Calculamos el cambio en la loss del discriminador\n",
    "    print('d_loss_prev:',d_loss_prev)\n",
    "    print('d_loss[0]:',d_loss[0])\n",
    "    d_loss_change = d_loss_prev - d_loss[0]\n",
    "    d_loss_prev = d_loss[0]\n",
    "    if d_loss_change > 0:\n",
    "        disc_batch_size = min(max(1, int(disc_batch_size * 0.9)),128)\n",
    "        print('disc_batch_size:max(1, int(disc_batch_size * 0.9)')\n",
    "    else:\n",
    "        disc_batch_size = min(int(disc_batch_size * 1.50),128)\n",
    "        print('disc_batch_size:int(disc_batch_size * 1.1)')\n",
    "        \n",
    "    print('disc_batch_size:',disc_batch_size)\n",
    "    ## Entrenamos generador\n",
    "        # Imágenes sintéticas\n",
    "    noise = np.random.normal(0, 1, (gen_batch_size, 100))\n",
    "    y_mislabled = np.ones((gen_batch_size, 1))\n",
    "        # Entremaos generador\n",
    "    g_loss = model_gan.train_on_batch(noise, y_mislabled)\n",
    "    ## Ajustamos tamaño de batch para generador\n",
    "    if g_loss < g_loss_prev:\n",
    "        gen_batch_size = min(int(gen_batch_size * 1.50),128)\n",
    "    else:\n",
    "        gen_batch_size = min(max(1, int(gen_batch_size * 0.9)),128)\n",
    "    g_loss_prev = g_loss\n",
    "    ## Evolución entrenamiento\n",
    "    print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))\n",
    "\n",
    "    DD_loss[cnt] = d_loss[0]\n",
    "    GG_loss[cnt] = g_loss\n",
    "\n",
    "    if cnt % sample_interval == 0:\n",
    "\n",
    "        # Generar imágenes falsas a partir de vectores de ruido aleatorios\n",
    "        noise = np.random.normal(0, 1, (num_classes, latent_dim))\n",
    "        images = model_gen.predict(noise)\n",
    "        print('images:',images.shape)\n",
    "             \n",
    "        images = 0.5 * images + 0.5 # escalar de [-1,1] a [0,1]\n",
    "        #images = np.uint8(255 * images) # escalar a [0, 255]\n",
    "        # Mostrar las imágenes generadas\n",
    "        r = 2\n",
    "        c = 5\n",
    "        fig, axs = plt.subplots(r, c,figsize=(11,6.9),dpi=100)\n",
    "        count = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(images[count, :, :,0],cmap='gray') #, cmap='gray'\n",
    "                axs[i,j].axis('off')\n",
    "                count += 1\n",
    "        plt.show()\n",
    "    #batch_D = int(batch/(d_loss[0]+1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t95OLxPEZVHO",
    "outputId": "2529e5b1-6fc8-4b61-c566-7dc152a5a1ca"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.figure\n",
    "plt.plot (GG_loss, label=\"Generator Loss\")\n",
    "plt.plot (DD_loss, label=\"Discriminator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vDZ9Pk5eIgD"
   },
   "source": [
    "Otra formaes modificar el tamaño de batch del discrimindor y del generador con las siguientes ecuaciones:\n",
    "\n",
    "- disc_batch_size = int(batch/(d_loss[0]+1e-8))\n",
    "- gen_batch_size =  int(batch/(g_loss+1e-8))\n",
    "\n",
    "Notar que el termino : +1e-8 se utiliza para evitar la división entre cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lU64Znje3LIt",
    "outputId": "d8e3c889-d05d-4025-f77f-16f0c5b0ef47"
   },
   "outputs": [],
   "source": [
    "model_gen = Sequential()\n",
    "model_gen.add (Dense (256, input_shape = (100,)))\n",
    "model_gen.add (LeakyReLU (alpha = 0.2))\n",
    "model_gen.add (BatchNormalization (momentum = 0.8))\n",
    "model_gen.add (Dense (512))\n",
    "model_gen.add (LeakyReLU (alpha = 0.2))\n",
    "model_gen.add (BatchNormalization (momentum = 0.8))\n",
    "model_gen.add (Dense(1024))\n",
    "model_gen.add (LeakyReLU (alpha=0.2))\n",
    "model_gen.add (BatchNormalization (momentum = 0.8))\n",
    "model_gen.add (Dense (np.prod (in_shape), activation = 'tanh'))\n",
    "model_gen.add (Reshape (in_shape))\n",
    "model_gen.summary ()\n",
    "model_gen.compile (loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "\n",
    "model_Disc = Sequential ()\n",
    "model_Disc.add (Flatten(input_shape = in_shape))\n",
    "model_Disc.add (Dense(128, input_shape = in_shape))\n",
    "model_Disc.add (LeakyReLU(alpha = 0.2))\n",
    "model_Disc.add (Dense(64))\n",
    "model_Disc.add (LeakyReLU(alpha = 0.2))\n",
    "model_Disc.add (Dense(1, activation = 'sigmoid'))\n",
    " \n",
    "model_Disc.compile (loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics = ['accuracy'])\n",
    "\n",
    "model_gan = Sequential()\n",
    "model_gan.add (model_gen)\n",
    "model_gan.add (model_Disc)\n",
    "model_gan.compile (loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, run_eagerly = True)\n",
    "\n",
    "\n",
    "model_gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gK8FPCAzBBbv",
    "outputId": "0ce368d8-ada6-4d79-d303-7bad603f7cd6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parámetros del entrenamiento\n",
    "epochs = 5000\n",
    "batch = 10\n",
    "gen_batch_size = batch\n",
    "disc_batch_size = batch/2\n",
    "\n",
    "sample_interval = 100\n",
    "num_classes     = 10\n",
    "latent_dim      = 100\n",
    "d_loss_prev     = np.inf\n",
    "g_loss_prev     = np.inf\n",
    "\n",
    "DD_loss = np.zeros((epochs,))\n",
    "GG_loss = np.zeros((epochs,))\n",
    "\n",
    "\n",
    "for cnt in range(epochs):\n",
    "\n",
    "    ## Entrenamos discriminador\n",
    "        # Imágenes reales\n",
    "    random_index = np.random.randint(0, len(X_train) - np.int64(disc_batch_size))\n",
    "    legit_images = X_train[random_index : random_index + np.int64(disc_batch_size)].reshape((np.int64(disc_batch_size),)+in_shape)\n",
    "        # Imágenes sintéticas\n",
    "    gen_noise = np.random.normal(0, 1, (np.int64(disc_batch_size), 100))\n",
    "    print('gen_noise:',gen_noise.shape)\n",
    "    syntetic_images = model_gen.predict(gen_noise)\n",
    "        # Combinamos imágenes reales y sintéticas\n",
    "    x_combined_batch = np.concatenate((legit_images, syntetic_images))\n",
    "    y_combined_batch = np.concatenate((np.ones((np.int64(disc_batch_size), 1)), np.zeros((np.int64(disc_batch_size), 1))))\n",
    "        # Entrenamos discriminador\n",
    "    d_loss = model_Disc.train_on_batch(x_combined_batch, y_combined_batch)\n",
    "   \n",
    "    # Calculamos el cambio en la loss del discriminador\n",
    "    print('d_loss_prev:',d_loss_prev)\n",
    "    print('d_loss[0]:',d_loss[0])\n",
    " \n",
    "    d_loss_prev = d_loss[0]\n",
    "    disc_batch_size = int(batch/(d_loss[0]+1e-8))\n",
    "         \n",
    "    print('disc_batch_size:',disc_batch_size)\n",
    "    ## Entrenamos generador\n",
    "        # Imágenes sintéticas\n",
    "    noise = np.random.normal(0, 1, (gen_batch_size, 100))\n",
    "    y_mislabled = np.ones((gen_batch_size, 1))\n",
    "        # Entremaos generador\n",
    "    g_loss = model_gan.train_on_batch(noise, y_mislabled)\n",
    "    \n",
    "    gen_batch_size =  int(batch/(g_loss+1e-8))\n",
    "  \n",
    "    ## Evolución entrenamiento\n",
    "    print ('epoch: %d, [Discriminator :: d_loss: %f], [ Generator :: loss: %f]' % (cnt, d_loss[0], g_loss))\n",
    "\n",
    "    DD_loss[cnt] = d_loss[0]\n",
    "    GG_loss[cnt] = g_loss\n",
    "\n",
    "    if cnt % sample_interval == 0:\n",
    "\n",
    "        # Generar imágenes falsas a partir de vectores de ruido aleatorios\n",
    "        noise = np.random.normal(0, 1, (num_classes, latent_dim))\n",
    "        images = model_gen.predict(noise)\n",
    "        print('images:',images.shape)\n",
    "             \n",
    "        images = 0.5 * images + 0.5 # escalar de [-1,1] a [0,1]\n",
    "        images = np.uint8(255 * images) # escalar a [0, 255]\n",
    "        # Mostrar las imágenes generadas\n",
    "        r = 2\n",
    "        c = 5\n",
    "        fig, axs = plt.subplots(r, c,figsize=(11,6.9),dpi=100)\n",
    "        count = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(images[count, :, :, 0], cmap='gray') #, cmap='gray'\n",
    "                axs[i,j].axis('off') \n",
    "                count += 1\n",
    "        plt.show()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hlnnznHZSXp",
    "outputId": "abcd584c-d678-46fa-f1cb-44327544c9c7"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.figure\n",
    "plt.plot (GG_loss, label=\"Generator Loss\")\n",
    "plt.plot (DD_loss, label=\"Discriminator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU2hejI1GYUX"
   },
   "source": [
    "# Generar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2CfT_0CM9br4",
    "outputId": "7b9982b3-a1ee-4cfd-a6b2-e6185d57d528"
   },
   "outputs": [],
   "source": [
    "# Generamos imagen sintética\n",
    "gen_noise = np.random.normal(0, 1, (np.int64(10), 100))\n",
    "syntetic_images = model_gen.predict(gen_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71mGdLt4Gcc_",
    "outputId": "7858ecb3-46a1-4564-9d55-e12178773f24"
   },
   "outputs": [],
   "source": [
    "# Mostramos imagen sintética\n",
    "plt.imshow(syntetic_images[4,:,:,0],cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXtwXgnlGdxY",
    "outputId": "bd871792-72f9-403d-e539-92c49351e25b"
   },
   "outputs": [],
   "source": [
    "# Esto es una imagen real (por comparar)\n",
    "plt.imshow(X_train[0,:,:,0],cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jcXQ5tzijvOM"
   },
   "source": [
    "### Ejercicio EXTRA:\n",
    "Crea un modelo que incluya todas las modificaciones de los cuatro ejercicios anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FKVUlTNOdVA8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "\n",
    "from tensorflow.keras import initializers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifXa2u4EdVPX"
   },
   "outputs": [],
   "source": [
    "# Visualizar imagenes-labels  \n",
    "def show_real_img (real_img,real_label,class_names,num_classes):\n",
    "    real_img = ((real_img + 1) * 127.5).astype(np.uint8)\n",
    "    fig, axes = plt.subplots (2, 5, figsize = (8, 3))\n",
    "    axes = axes.flatten ()\n",
    "    for i in range (num_classes):\n",
    "        idx = np.where (real_label [:] == i)[0]\n",
    "        features_idx = real_img [idx, ::]\n",
    "        img_num = np.random.randint (features_idx.shape [0])\n",
    "        img = features_idx[img_num, ::]\n",
    " \n",
    "        axes [i].imshow (img [:,:,::-1]) #img [:,:,::-1].reshape(28, 28), cmap='gray')\n",
    "        axes [i].set_title (class_names [i])   \n",
    "        axes [i].axis ('off')   \n",
    "    plt.tight_layout ()\n",
    "    plt.show ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0jC5DE9LMi9",
    "outputId": "ffb95921-c0e4-4918-d78c-0130254c89bd"
   },
   "outputs": [],
   "source": [
    "# Definir las variables relevantes\n",
    "# Datos\n",
    "# Load cifar10  \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog',\n",
    "                'frog','horse','ship','truck']\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    " \n",
    "# Normalizamos a 0-255\n",
    "# X_train = X_train.astype('float32') / 255.0\n",
    "\n",
    "# Visualizar imagenes cargadas del dataset\n",
    "show_real_img (X_train,y_train,class_names,num_classes)\n",
    "\n",
    "print('X_train shape 2:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VxaBsY_TLMi-",
    "outputId": "aa8ae163-6955-4341-c9fb-0401e84edacf"
   },
   "outputs": [],
   "source": [
    "idx = np.array([3, 4, 0, 7, 2, 3, 0, 4, 8, 3])\n",
    "np.array(class_names)[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMV9Qn6mdVT1"
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# Datos para el modelo y el entrenamiento\n",
    "#----------------------------------------\n",
    "\n",
    "# Definir dimensiones de entrada\n",
    "in_shape   = (32, 32, 3)\n",
    "img_dim    = np.prod (in_shape)\n",
    "init       = initializers.RandomNormal (stddev = 0.02)\n",
    "latent_dim = 100\n",
    " \n",
    "#optimizador\n",
    "OPTIMZADOR_ADAM = Adam (learning_rate = 0.0002, beta_1 = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "pXRC4wvLdVWy",
    "outputId": "bc3a4bc6-cc18-416a-ebfb-a5f63d3fb7f0"
   },
   "outputs": [],
   "source": [
    "# ***********************************\n",
    "# Definir modelo generador\n",
    "# ***********************************\n",
    "generator = Sequential ()\n",
    "## Input layer  \n",
    "generator.add(Dense(256, input_shape=(latent_dim,))) # , kernel_initializer=init\n",
    "generator.add(BatchNormalization( momentum=0.8)) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(Dense(128 )) # , kernel_initializer=init\n",
    "generator.add(BatchNormalization( momentum=0.8)) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(Dense(128 )) # , kernel_initializer=init\n",
    "generator.add(BatchNormalization( momentum=0.8)) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "generator.add(Dense(64))\n",
    "generator.add(BatchNormalization()) # momentum=0.8\n",
    "generator.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    " \n",
    "generator.add(Dense(np.prod(in_shape), activation='tanh'))\n",
    "generator.add(Reshape(in_shape))\n",
    "\n",
    "# se pasa también la eiqueta de la imagen\n",
    "# Create label embeddings, one-hot (label)\n",
    "label = Input (shape = (1,), dtype = 'int32')\n",
    "label_embedding = Embedding (num_classes, latent_dim)(label)\n",
    "label_embedding = Flatten ()(label_embedding)\n",
    "\n",
    "# latent space\n",
    "z = Input (shape = (latent_dim,))\n",
    "\n",
    "# Output image\n",
    "img = generator (Multiply ()([z, label_embedding]))\n",
    "\n",
    "# Generator with condition input\n",
    "generator = Model ([z, label], img)\n",
    "generator.summary ()\n",
    "plot_model (generator, to_file = 'cgan_generator.png', show_shapes = True)\n",
    "\n",
    "# ***********************************\n",
    "# Definir modelo discriminador\n",
    "# ***********************************\n",
    "\n",
    "# Discriminator network\n",
    "discriminator = Sequential()\n",
    " \n",
    "# Input layer  \n",
    " \n",
    "# Input layer  \n",
    "discriminator.add(Flatten(input_shape=in_shape))\n",
    "discriminator.add(Dense(64, input_shape=in_shape)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(128)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(128)) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "#discriminator.add(Dropout(0.2))\n",
    "discriminator.add(Dense(256 )) # , kernel_initializer=init\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "#discriminator.add(BatchNormalization()) # momentum=0.8\n",
    "discriminator.add(Dropout(0.3))\n",
    "# Output layer\n",
    " \n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# se pasa también la eiqueta de la imagen\n",
    "label_d = Input(shape = (1,), dtype = 'int32')\n",
    "label_embedding_d = Embedding (num_classes, img_dim)(label_d)\n",
    "label_embedding_d = Flatten ()(label_embedding_d)\n",
    "label_embedding_d = Reshape (in_shape)(label_embedding_d)\n",
    " \n",
    "# image dimension 32x32\n",
    "# Image input\n",
    "img_d = Input (shape = in_shape)\n",
    "# Output image\n",
    "validity = discriminator (Multiply()([img_d, label_embedding_d]))\n",
    "\n",
    "# Discriminator with condition input\n",
    "discriminator = Model([img_d, label_d], validity)\n",
    "discriminator.summary()\n",
    "plot_model(discriminator, to_file='cgan_discriminator.png', show_shapes=True)\n",
    "# Compilar modelos\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM, metrics=['accuracy'])\n",
    "#generator.compile(loss='binary_crossentropy', optimizer=OPTIMZADOR_ADAM)\n",
    "\n",
    "# ***********************************\n",
    "# Definir modelo cGan\n",
    "# ***********************************\n",
    "gen_input = Input (shape = (latent_dim,))\n",
    "gen_label = Input (shape = (1,), dtype='int32')\n",
    "\n",
    "synthetic_image = generator ([gen_input, gen_label])\n",
    "synthetic_image_reshaped = Reshape (in_shape)(synthetic_image)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator ([synthetic_image_reshaped, gen_label])\n",
    "\n",
    "cGan = Model ([gen_input, gen_label], validity)\n",
    "cGan.summary ()\n",
    "plot_model (cGan, to_file = 'cgan_model.png', show_shapes = True)\n",
    "cGan.compile (loss = 'binary_crossentropy', optimizer = OPTIMZADOR_ADAM, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27U6xWaFdVai",
    "outputId": "43591d16-4a31-4a4c-b5bc-16c5c3add074",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parámetros del entrenamiento\n",
    "epochs     = 20000 \n",
    "batch_size = 128\n",
    "\n",
    "# Bucle entrenamiento\n",
    "DD_loss = np.zeros ((epochs+1,))\n",
    "GG_loss = np.zeros ((epochs+1,))\n",
    " \n",
    "ones  = np.ones ((batch_size, 1))\n",
    "zeros = np.zeros ((batch_size,1))\n",
    "\n",
    "for cnt in range (epochs + 1):\n",
    "   \n",
    "    # ***********************************\n",
    "    # Paso 1: Entrenar el discriminador\n",
    "    discriminator.trainable = True\n",
    "    # ***********************************\n",
    "    \n",
    "    \n",
    "    # Genera un conjunto de imágenes reales\n",
    "    idx = np.random.randint (0, X_train.shape [0], size = batch_size)\n",
    "    #idx0 = cnt*batch_size\n",
    "    #idx1 = (cnt+1)*batch_size\n",
    "\n",
    "    real_images = X_train [idx] # batch_size imageners normalizadas entre [-1,1]\n",
    "    real_labels = y_train [idx] #y_train[idx0:idx1] \n",
    "\n",
    "    # Genera un conjunto de imágenes falsas\n",
    "    noise = np.random.normal (0, 1, (batch_size, latent_dim)) \n",
    "    fake_labels = np.random.randint (0, num_classes, batch_size).reshape (-1,1) \n",
    "    fake_images = generator.predict ([noise,fake_labels])\n",
    "    #print(fake_images.shape)\n",
    "    fake_images = np.reshape (fake_images, (fake_images.shape [0], 32, 32, 3))\n",
    "    \n",
    "    # Entrenamiento discriminador\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch ([real_images, real_labels], ones)\n",
    "    d_loss_fake = discriminator.train_on_batch ([fake_images, fake_labels], zeros)\n",
    "    d_loss = 0.5 * np.add (d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ***********************************\n",
    "    # Paso 2: Entrenar el generador\n",
    "    discriminator.trainable = False\n",
    "    # ***********************************\n",
    "    gen_input  = np.random.normal (0, 1, (batch_size, latent_dim))\n",
    "    gen_labels = np.random.randint (0, num_classes, batch_size).reshape (-1,1)  \n",
    "    \n",
    "    g_loss = cGan.train_on_batch ([gen_input, gen_labels], ones)\n",
    "\n",
    "    # Registrar el progreso del entrenamiento\n",
    "    DD_loss[cnt] = d_loss [0]\n",
    "    GG_loss[cnt] = g_loss [0]\n",
    "\n",
    "    print(f'Epoch: {cnt}/{epochs} \\t Discriminator Loss: {d_loss[0]} \\t Generator Loss: {g_loss[0]}')\n",
    "    # Imprimir progreso cada 100 iteraciones\n",
    "    if cnt % 100 == 0:\n",
    "        print (y_train.shape)\n",
    "         # Rescale images 0 - 1\n",
    "        real_images = 0.5 * real_images + 0.5\n",
    "        real_images = (real_images* 255).astype(np.uint8)\n",
    "        #show_real_img (real_images, real_labels, class_names, num_classes)\n",
    "        \n",
    "        samples = 10\n",
    "        z = np.random.normal(loc=0, scale=1, size=(samples, latent_dim))\n",
    "        \n",
    "        labels = np.arange(0, num_classes).reshape (-1,1) \n",
    "        \n",
    "\n",
    "        x_fake = generator.predict([z, labels])\n",
    "        x_fake =  np.reshape (x_fake, (x_fake.shape[0], 32, 32, 3))\n",
    "        show_real_img (x_fake, labels, class_names, num_classes)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnvaaoBu3LIv",
    "outputId": "cc5d7ea9-c33a-4d3c-e385-a6fa813248e1"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure\n",
    "plt.plot(DD_loss, label=\"Discriminator Loss\")\n",
    "plt.plot(GG_loss, label=\"Generator Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0OPMhHobLMi_",
    "outputId": "baa23365-1aab-4fa4-d403-9457cd8f2495"
   },
   "outputs": [],
   "source": [
    "# Generar imágenes con etiquetas aleatorias\n",
    "n_to_show   = 10\n",
    "latent_dim  = 100\n",
    "num_classes = 10\n",
    "\n",
    "z = np.random.normal (loc = 0, scale = 1, size = (n_to_show, latent_dim))\n",
    "fake_labels = np.random.randint (0, num_classes, n_to_show).reshape (-1,1)\n",
    "x_fake = generator.predict ([z, fake_labels])\n",
    "x_fake =  np.reshape(x_fake, (x_fake.shape [0], 32, 32, 3))\n",
    "x_fake = 0.5 * x_fake + 0.5 # escalar de [-1,1] a [0,1]\n",
    "x_fake = np.uint8(255 * x_fake).astype(np.uint8) # escalar a [0, 255]\n",
    "\n",
    "# Mostrar imágenes generadas con sus etiquetas\n",
    "fig, axs = plt.subplots(1, n_to_show, figsize=(20,6.9),dpi=100)\n",
    "for i in range(n_to_show):\n",
    "    axs[i].set_title(f'Label: {class_names[i]}')\n",
    "    axs[i].imshow(x_fake[i, :,:])\n",
    "    axs[i].axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaR9H5hb3LIw"
   },
   "source": [
    "Volvemos a ver que exclusivamente con capas densas, y aún incluyendo más información como es el label de la imagen, la red no es capaz de acercarse a la imagen real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79K9bDFSLMi_"
   },
   "source": [
    "# Con capas convolucionales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BUBPKphbLMi_"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import tensorflow as tf \n",
    "\n",
    "from keras import initializers\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Multiply, concatenate\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D, concatenate, MaxPool2D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OGgh4HI4ifKL"
   },
   "outputs": [],
   "source": [
    "#----------------------------------------\n",
    "# Datos para el modelo y el entrenamiento\n",
    "#----------------------------------------\n",
    "\n",
    "# Definir dimensiones de entrada\n",
    "in_shape          = (32, 32, 3)\n",
    "img_dim           = np.prod (in_shape)\n",
    "init              = initializers.RandomNormal (stddev = 0.02)\n",
    "x_init            = tf.keras.initializers.GlorotUniform ()\n",
    "x2_init           = tf.keras.initializers.GlorotNormal ()\n",
    "OPTIMZADOR_ADAM   = Adam (learning_rate = 0.0002, beta_1 = 0.5)# learning_rate=0.0005, \n",
    "OPTIMZADOR_RMSPRO =  tf.keras.optimizers.experimental.RMSprop (learning_rate = 0.002)\n",
    "\n",
    "EPOCHS        = 2\n",
    "batch_size    = 256\n",
    "latent_dim    = 100\n",
    "embedding_dim = 28 #50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhqy_8Pxi5cv",
    "outputId": "662d5de8-a520-412d-95f6-459b588a47a8"
   },
   "outputs": [],
   "source": [
    "# Definir las variables relevantes\n",
    "# Datos\n",
    "# Load cifar10  \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "class_names = ['airplane','automobile','bird','cat','deer','dog',\n",
    "                        'frog','horse','ship','truck']\n",
    "\n",
    "\n",
    "\n",
    "# Rescale -1 to 1\n",
    "X_train, X_test = X_train.astype('float32')/127.5 - 1, X_test.astype('float32')/127.5 - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9uL_T26LMi_"
   },
   "outputs": [],
   "source": [
    "# Visualizar imagenes-labels  \n",
    "def show_real_img_rand (real_img,real_label,class_names,num_classes):\n",
    "    print(\"show_real_img_rand\")\n",
    "\n",
    "    fig, axes = plt.subplots (2, 5, figsize = (8, 3))\n",
    "    axes = axes.flatten ()\n",
    "    for i in range (num_classes):\n",
    "        idx = np.where (real_label [:] == i)[0]                # buscamos label 'i'\n",
    "        features_idx = real_img [idx, ::]                      # buscamos las posiciones de las imagenes del label 'i'\n",
    "        img_num = np.random.randint (features_idx.shape [0])   # cogemos el primer batch q tiene esa posición\n",
    "    \n",
    "        img = features_idx[img_num, ::]\n",
    "\n",
    "        img = (((img) + 1) * 127.5).astype(np.uint8)\n",
    "\n",
    "        axes [i].imshow (img [:,:,::-1]) #img [:,:,::-1]\n",
    "        axes [i].set_title (class_names [i])   \n",
    "        #axes [i].axis ('off')   \n",
    "    plt.tight_layout ()\n",
    "    plt.show ()\n",
    "    \n",
    "def show_real_img (real_img, real_label, class_names, num_classes):\n",
    "    print (\"*> show_real_img: \")\n",
    "    lbls_img  = real_label [0:num_classes].ravel()\n",
    "    names_img = [class_names [i] for i in  real_label [0:num_classes].ravel()]\n",
    "    fig, axes = plt.subplots (2, 5, figsize = (8, 3))\n",
    "    axes = axes.flatten ()\n",
    "    for i  in range  (num_classes):\n",
    "        img = ((real_img [i,:,:,::-1] + 1) * 127.5).astype(np.uint8)  \n",
    "        axes [i].imshow (img)  \n",
    "        axes [i].set_title (names_img[i])   \n",
    "        #axes [i].axis ('off')   \n",
    "    plt.tight_layout ()\n",
    "    plt.show ()     \n",
    "    \n",
    "def show_predict_img (generator, class_names, num_classes, batch_size, latent_dim):\n",
    "  print (\"*> show_predict_img: \" )\n",
    "  try: \n",
    "\n",
    "    # Generar ruido y etiquetas aleatorias\n",
    " \n",
    "\n",
    "    fake_label = np.random.randint(0, num_classes, size = batch_size).reshape (-1,1)\n",
    "    \n",
    "    lbls_img  = fake_label [0:num_classes].ravel()\n",
    "    names_img = [class_names [i] for i in  fake_label [0:num_classes].ravel()]\n",
    "\n",
    "    z = np.random.normal (loc = 0, scale = 1, size = (batch_size, latent_dim))\n",
    "    z = np.clip (z, -1, 1)\n",
    "    print (z.shape)\n",
    "    print (fake_label.shape)\n",
    "    x_fake = generator.predict ([z, fake_label])\n",
    "\n",
    "    fig, axes = plt.subplots (2, 5, figsize = (8, 3))\n",
    "    axes = axes.flatten ()\n",
    "    for i  in range  (num_classes):\n",
    "        img = ((x_fake [i,:,:,::-1] + 1) * 127.5).astype(np.uint8)  \n",
    "        axes [i].imshow (img)  \n",
    "        axes [i].set_title (names_img [i])   \n",
    "        axes [i].axis ('off')   \n",
    "    plt.tight_layout ()\n",
    "    plt.show ()\n",
    "\n",
    "  except Exception as inst:\n",
    "    print(type(inst))    # the exception type\n",
    "    print(inst.args)     # arguments stored in .args\n",
    "    print(inst)        \n",
    "    x = inst.args     # unpack args\n",
    "    print('x =', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gPpSDfus3LIw",
    "outputId": "600cc5b1-465c-4eea-f77e-736b121147de"
   },
   "outputs": [],
   "source": [
    "### # define the standalone generator model\n",
    " \n",
    "# Función para crear el generador\n",
    "def create_generator(num_classes, latent_dim = 100,  embedding_dim = 28):\n",
    "    # Entrada de ruido y label\n",
    "   \n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    in_label = Input(shape=(1,))\n",
    "    le = Flatten()(Embedding(num_classes, embedding_dim)(in_label))\n",
    " \n",
    "    m_nn      = 256\n",
    "    n_nodes   = m_nn * 4 * 4\n",
    "    dim_nodes = 4, 4, m_nn \n",
    "    # Concatenar ruido y etiqueta\n",
    "    inputs = concatenate ([noise, le])\n",
    "\n",
    "    # Creo la red del generador\n",
    "    x = inputs\n",
    "     \n",
    "    #x = Dense (m_nn)(x)\n",
    "    # Capa completamente conectada\n",
    "    x = Dense (n_nodes)(x)\n",
    "    x = Reshape (dim_nodes)(x)\n",
    "    \n",
    "    # Capas de deconvolución 8x8\n",
    "    x = Conv2DTranspose (128, (4, 4), strides=(2, 2), padding='same')(x)\n",
    "    #x = BatchNormalization ()(x) #momentum = 0.9\n",
    "    #x = MaxPool2D ( )(x)\n",
    "    x = LeakyReLU (alpha = 0.2)(x)\n",
    "    \n",
    "    # Capas de deconvolución 16x16\n",
    "    x = Conv2DTranspose (128 , (4, 4), strides = (2,2), padding = 'same')(x)\n",
    "    #x = BatchNormalization ( )(x) #momentum = 0.9\n",
    "    #x = MaxPool2D ( )(x)\n",
    "    x = LeakyReLU (alpha = 0.2)(x)\n",
    "\n",
    "    # Capas de deconvolución 32x32\n",
    "    x = Conv2DTranspose (128 , (4, 4), strides = (2, 2), padding = 'same')(x)\n",
    "    #x = BatchNormalization (momentum = 0.9 )(x) # momentum = 0.9\n",
    "    #x = MaxPool2D ( )(x)\n",
    "    x = LeakyReLU (alpha = 0.2)(x)\n",
    "    \n",
    "    \n",
    "    #x = Conv2DTranspose (256  , (5, 5), strides = (2, 2), padding = 'same')(x)\n",
    "    #x = BatchNormalization (momentum = 0.8)(x)\n",
    "    #x = MaxPool2D ( )(x)\n",
    "    #x = LeakyReLU (alpha = 0.2)(x)\n",
    "  \n",
    "        \n",
    "    # Capa de salida\n",
    "    output = Conv2DTranspose (3, (3, 3), strides = (1, 1), padding = 'same', activation = 'tanh')(x)\n",
    "    \n",
    "    # Crear modelo\n",
    "    generator = Model([noise, in_label], output)\n",
    "    generator.compile (loss = 'binary_crossentropy', optimizer = Adam (learning_rate = 0.002, beta_1 = 0.5) )\n",
    "\n",
    "    return generator\n",
    "\n",
    "# Crear generador\n",
    " \n",
    "generator = create_generator(latent_dim = latent_dim, num_classes = num_classes)\n",
    " \n",
    "generator.summary()\n",
    "    \n",
    "\n",
    "# Función para construir el discriminador condicional\n",
    "def define_discriminator (in_shape = (32, 32, 3), n_classes = 10):\n",
    "    in_label =  Input (shape = (1,))\n",
    "    \n",
    "    le = Embedding (num_classes, img_dim)(in_label)\n",
    "    le = Flatten ()(le)\n",
    "    le = Reshape (in_shape)(le)\n",
    "    \n",
    "    in_image =  Input (shape =  in_shape)\n",
    "    merge    =  concatenate ([in_image, le])\n",
    "     \n",
    " \n",
    "    x = Dense (64, kernel_initializer = init) (merge)\n",
    "   \n",
    "    # downsample\n",
    "    fe = Conv2D (128 , (3, 3), strides = (2, 2), padding = 'same')(x)\n",
    "    fe = LeakyReLU (alpha = 0.2)(fe)\n",
    "    #fe = Dropout (0.4)(fe)\n",
    "    \n",
    "    # downsample\n",
    "    fe = Conv2D (128 , (3, 3), strides = (2, 2), padding = 'same')(fe)\n",
    "    fe = LeakyReLU (alpha = 0.2)(fe)\n",
    "    #fe = Dropout (0.4)(fe)\n",
    "     \n",
    "    \n",
    "    # downsample\n",
    "    fe = Conv2D (128 , (3, 3), strides = (2, 2), padding = 'same')(fe)\n",
    "    fe = LeakyReLU (alpha = 0.2)(fe)\n",
    "    #fe = Dropout (0.4)(fe)\n",
    "   \n",
    "    \n",
    "    # downsample\n",
    "    fe = Conv2D (128 , (3, 3), strides = (2, 2), padding = 'same')(fe)\n",
    "    fe = LeakyReLU (alpha = 0.2)(fe)\n",
    "    fe = Dropout (0.4)(fe)\n",
    "    fe = Flatten ()(fe)\n",
    " \n",
    "    fe = Dense (256, activation = 'relu')(fe)\n",
    "    fe = Dense (256, activation = 'relu')(fe)\n",
    "    \n",
    "    fe = Dropout (0.4)(fe)\n",
    "        \n",
    "    out_layer =  Dense (1, activation = 'sigmoid')(fe)\n",
    "    model     =  Model ([in_image, in_label], out_layer)\n",
    "    \n",
    "    model.compile (loss = 'binary_crossentropy', optimizer = Adam (learning_rate = 0.0004, beta_1 = 0.5), metrics = ['accuracy'])  \n",
    "    \n",
    "    return model\n",
    " \n",
    "discriminator = define_discriminator(in_shape, num_classes)\n",
    "discriminator.summary()\n",
    "\n",
    "#define the Conditional GAN\n",
    "def define_gan (generator, discriminator):\n",
    "    #make discriminator non trelue\n",
    "    discriminator.trainable = False\n",
    "    #get noise and label from generator\n",
    "    gen_noise, gen_label = generator.input\n",
    " \n",
    "    #get output from generator\n",
    "    gen_output = generator.output\n",
    "  \n",
    "    #connect image and label input from generator as inputs to discriminator\n",
    "    gan_output = discriminator ([gen_output, gen_label])\n",
    "    #define the GAN model. \n",
    "  \n",
    "    model =  tf.keras.Model ([gen_noise, gen_label], gan_output)\n",
    "    #compile model\n",
    " \n",
    "    model.compile (loss='binary_crossentropy', optimizer = Adam (learning_rate = 0.0005, beta_1 = 0.5), metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "cGan = define_gan(generator, discriminator)\n",
    "cGan.summary()\n",
    "\n",
    "def get_real_images (batch_size):\n",
    "    print (\"REAL _IMAGENES\")\n",
    "    #(X_train, y_train), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "    # Rescale -1 to 1\n",
    "    #X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "    idx = np.random.randint (0, X_train.shape[0], batch_size)\n",
    "    real_images = X_train [idx]\n",
    "    real_label  = y_train [idx].reshape (-1, 1) \n",
    "    \n",
    "    #show_real_img_ (real_images,real_label,class_names,num_classes)\n",
    "    \n",
    "    return real_images, real_label\n",
    "\n",
    "def get_fake_labels (batch_size):\n",
    "    \"\"\"\n",
    "    Genera etiquetas falsas para las imágenes falsas generadas por el generador del modelo GAN.\n",
    "\n",
    "    Parameters:\n",
    "        - batch_size (int): Tamaño del batch de imágenes a generar.\n",
    "\n",
    "    Returns:\n",
    "        - fake_labels (array): Array de etiquetas falsas generadas para las imágenes falsas.\n",
    "    \"\"\"\n",
    "    fake_labels = np.random.randint (0, num_classes, batch_size) \n",
    "    #labels_one_hot = to_categorical(fake_labels, num_classes = num_classes)\n",
    "    return fake_labels.reshape (-1, 1) \n",
    "# Función para generar un batch de imágenes falsas junto con sus labels\n",
    "def get_fake_images (batch_size, latent_dim):\n",
    "    \"\"\"\n",
    "    Genera imágenes falsas utilizando el generador del modelo GAN.\n",
    "\n",
    "    Parameters:\n",
    "        - batch_size (int): Tamaño del batch de imágenes a generar.\n",
    "        - latent_dim (int): Dimensión del espacio latente.\n",
    "\n",
    "    Returns:\n",
    "        - fake_images (array): Array de imágenes falsas generadas por el generador.\n",
    "        - fake_labels (array): Array de etiquetas falsas generadas para las imágenes falsas.\n",
    "    \"\"\"\n",
    " \n",
    "    print (\"FAKE_IMAGENES\")\n",
    "\n",
    "    # Generar ruido y etiquetas aleatorias\n",
    "    noise  = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "    #noise  = (noise.astype(np.float32) - 127.5) / 127.5\n",
    "    noise = np.clip (noise, -1, 1)\n",
    "    fake_labels = get_fake_labels (batch_size)\n",
    "    # Llamar al generador para generar imágenes. los valores de píxeles de encuentran entre (-1, 1). recordar que la f.Actv es tanh\n",
    "    fake_images = generator.predict([noise, fake_labels])\n",
    "    # Escalar los valores de píxeles a (0, 255)\n",
    "    #fake_images = 127.5 * generated_images + 127.5\n",
    " \n",
    "    return fake_images, fake_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 994
    },
    "id": "L2m-UTkSwAcM",
    "outputId": "8ff8abba-901e-4bdc-a397-7004f0375890"
   },
   "outputs": [],
   "source": [
    "show_real_img_rand (X_train, y_train, class_names, num_classes)\n",
    "\n",
    "show_real_img (X_train, y_train, class_names, num_classes)\n",
    "\n",
    "show_predict_img (generator, class_names, num_classes, num_classes, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkWPUyV03LIx"
   },
   "source": [
    "## ***TRAIN***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iu_Y7uzI3LIy"
   },
   "source": [
    "1. Definimos las variables \"gen_batch_size\" y \"disc_batch_size\" que serán las que determinen el tamaño del batch de cada modelo en cada iteración del bucle de entrenamiento. Establecemos su valor inicial en \"batch\", el tamaño de batch original.\n",
    "\n",
    "3. En cada iteración del bucle de entrenamiento, calculamos el coste (loss) de cada modelo en la iteración anterior y lo almacenamos en las variables \"d_loss_prev\" y \"g_loss_prev\".\n",
    "\n",
    "3. Para el discriminador, comparamos su coste anterior con el coste actual y, si ha mejorado, reducimos el tamaño del batch en un 10%, mientras que si ha empeorado, lo aumentamos en un 10%. En cualquier caso, aseguramos que el tamaño mínimo del batch sea 1.\n",
    "\n",
    "4. Para el generador, hacemos lo mismo que para el discriminador pero con la inversa, es decir, si ha mejorado aumentamos el tamaño del batch y si ha empeorado lo reducimos.\n",
    "\n",
    "5. Utilizamos los tamaños de batch calculados para entrenar los modelos en cada iteración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xYD0HrNbpeNl",
    "outputId": "040a1b81-3291-47e1-976d-07ae7d472f62",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS        = 100\n",
    "batch_size    = 256\n",
    "latent_dim    = 100\n",
    "embedding_dim = 28\n",
    "smooth        = 0.1\n",
    "\n",
    "real = np.ones  (shape = (batch_size, 1))\n",
    "fake = np.zeros (shape = (batch_size, 1))\n",
    "\n",
    "d_loss = []\n",
    "g_loss = []\n",
    "DD_loss  = []\n",
    "GG_loss  = []\n",
    "for e in range(EPOCHS + 1):\n",
    "    for i in range(len(X_train) // batch_size):\n",
    "        # Paso 1: Entrenar el discriminador\n",
    "        discriminator.trainable = True\n",
    "\n",
    "        # Genera un conjunto de imágenes reales\n",
    "        idx = np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "        real_images = X_train[idx]\n",
    "        real_labels = y_train[idx]\n",
    "\n",
    "        # Genera un conjunto de imágenes falsas\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        noise = np.clip(noise, -1, 1)\n",
    "        fake_labels = np.random.randint(0, num_classes, batch_size)\n",
    "        fake_images = generator.predict([noise, fake_labels])\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch([real_images, real_labels], real * (1 - smooth))\n",
    "        d_loss_fake = discriminator.train_on_batch([fake_images, fake_labels], fake)\n",
    "        d_loss_batch = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        d_loss.append(d_loss_batch)\n",
    "\n",
    "        # Paso 2: Entrenar el generador\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        gen_input = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        gen_input = np.clip(gen_input, -1, 1)\n",
    "        gen_labels = np.random.randint(0, num_classes, batch_size)\n",
    "\n",
    "        g_loss_batch = cGan.train_on_batch([gen_input, gen_labels], real)\n",
    "        g_loss.append(g_loss_batch)\n",
    "\n",
    "    # Registrar el progreso del entrenamiento\n",
    "    DD_loss.append(np.mean(d_loss, axis=0))\n",
    "    GG_loss.append(np.mean(g_loss, axis=0))\n",
    "    print(f'Epoch: {e}/{EPOCHS} \\t Discriminator Loss: {DD_loss[0]} \\t Generator Loss: {GG_loss[0]}')\n",
    "\n",
    "    # Reiniciar las listas de pérdida para la siguiente época\n",
    "    d_loss = []\n",
    "    g_loss = []\n",
    "\n",
    "    # Imprimir progreso cada 10 iteraciones\n",
    "    #if e % 5 == 0:\n",
    "    show_predict_img (generator, class_names, num_classes, num_classes, latent_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "oFV1BoibLMjA",
    "outputId": "d6842578-4380-43c0-e570-982a78cad78f"
   },
   "outputs": [],
   "source": [
    "### %matplotlib inline\n",
    "plt.figure ()\n",
    "plt.plot (DD_loss , label = \"Discriminator\")\n",
    "plt.plot (GG_loss  , label = \"Generator\")\n",
    "plt.legend ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "id": "bocdPHONLMjA",
    "outputId": "02d1efe3-6828-44aa-9101-a23cf0fb0b4d"
   },
   "outputs": [],
   "source": [
    "# Generar imágenes con etiquetas aleatorias\n",
    "n_to_show   = 15\n",
    "latent_dim  = 100\n",
    "num_classes = 10\n",
    "show_predict_img (generator, class_names, num_classes, n_to_show, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxBKQgHqLMjA"
   },
   "source": [
    "#### Pruebas de GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "932YMQrbLMjA",
    "outputId": "00bb31c3-bbc8-400d-f789-fc9c1802a1b5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrlbekK6LMjB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):  # GPUが使えたら利用する\n",
    "    device_name = tf.test.gpu_device_name()\n",
    "else:\n",
    "    device_name = '/CPU:0'\n",
    "    \n",
    "print(device_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BY555yGE3LIz"
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Limitación la memoria de la GPU\n",
    "config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.6\n",
    "tf.compat.v1.keras.backend.set_session (tf.compat.v1.Session(config=config))\n",
    "\n",
    "# Permitir crecimiento de la memoria\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    print('Invalid device or cannot modify virtual devices once initialized.')\n",
    "\n",
    "\n",
    "print('#### INFORMACIÓN ####')\n",
    "print('  Versión de TensorFlow: {}'.format(tf.__version__))\n",
    "#print('  GPU: {}'.format([(x.name, x.physical_device_desc)\n",
    "#                          for x in tf.python.client.device_lib.list_local_devices() if x.device_type == 'GPU']))\n",
    "print( tf.sysconfig.get_build_info() )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DD5VKw2W3LIz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6qqOtEW3LIz"
   },
   "outputs": [],
   "source": [
    " \n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow está usando GPU.\")\n",
    "else:\n",
    "    print(\"TensorFlow está usando CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VvVwKmof3LIz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Ajustar la asignación de memoria de TensorFlow para todas las GPUs disponibles en el sistema\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    # Manejar error\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClR1fRl23LIz"
   },
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "libs = [\"protobuf\",\"tfds-nightly\",\"googleapis-common-protos\", \"mediapipe\",\n",
    "        \"tb-nightly\", \"tensorboard\", \"tensorflow\", \"tensorflow-gpu\",\"tensorflow-intel\", \"tensorflow-metadata\", \n",
    "        \"tf_nightly_intel\"]\n",
    "\n",
    "[lb+' = '+pkg_resources.get_distribution(lb).version for lb in libs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8IChsAtpeNu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_P_dy6B3peNu"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Imprimir todas las variables de entorno\n",
    "#print(os.environ)\n",
    "\n",
    "# Acceder a una variable de entorno específica\n",
    "valor_variable = os.environ.get ('CUDA_HOME')\n",
    "print(valor_variable)\n",
    "valor_variable = os.environ.get ('PATH')\n",
    "print(valor_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkQ4ZYXQpeNu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.sysconfig.get_build_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSgsa9nepeNu",
    "outputId": "03d04961-f0f3-421e-a3d0-3a05a0b62509"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.set_visible_devices(tf.config.list_physical_devices('GPU'), 'GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kk9RYF35peNu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
